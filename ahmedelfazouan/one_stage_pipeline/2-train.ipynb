{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "datadir = './preprocessed'\n",
    "libdir = '.'\n",
    "outputdir = './ax_t2_soft_90_256'\n",
    "otherdir = '.'\n",
    "train_bs_ = 4\n",
    "valid_bs_ = 4\n",
    "num_workers_ = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i for i in timm.list_models() if 'resnest' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conditions = ['spinal_canal_stenosis', 'left_neural_foraminal_narrowing', 'right_neural_foraminal_narrowing',\n",
    "          'left_subarticular_stenosis', 'right_subarticular_stenosis']\n",
    "levels = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n",
    "severity = ['Normal/Mild', 'Moderate', 'Severe']\n",
    "class CFG:\n",
    "    seed=42\n",
    "    device='GPU'\n",
    "    nprocs=1 # [1, 8]\n",
    "    num_workers=num_workers_\n",
    "    train_bs=train_bs_\n",
    "    valid_bs=valid_bs_\n",
    "    data_dir = './'\n",
    "    INP_DIR = 'rsna/'\n",
    "    target_cols=[c+'_'+l+'_'+s for c in conditions for l in levels for s in severity]\n",
    "    imgs_dir = ['./input/']\n",
    "    num_classes=75\n",
    "\n",
    "    accum_iter=1#2\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    normalize_mean=[0.4824, 0.4824, 0.4824] # [0.485, 0.456, 0.406] [0.4824, 0.4824, 0.4824]\n",
    "    normalize_std=[0.22, 0.22, 0.22] # [0.229, 0.224, 0.225] [0.22, 0.22, 0.22]\n",
    "\n",
    "    suffix=\"440\"\n",
    "    fold_num=4\n",
    "    fold_list=[0, 1, 2, 3]\n",
    "    min_epoch = -1\n",
    "    epochs = 40\n",
    "    shift_epoch = 1000\n",
    "    model_arch=\"resnest50d\" # tf_efficientnetv2_s, resnest50d, resnext50_32x4d, resnet200d, convnext_tiny_384_in22ft1k\n",
    "    optimizer=\"AdamW\" # Adam, SGD, AdamW\n",
    "    scheduler=\"CosineAnnealingLR\"#'ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts'\n",
    "    loss_fn= \"Custom_loss\"#'Custom_loss', \"BCEWithLogitsLoss\", \"FocalLoss\"\n",
    "    scheduler_warmup=\"GradualWarmupSchedulerV3\" \n",
    "\n",
    "    warmup_epo=1\n",
    "    warmup_factor = 10\n",
    "    T_0 = 1\n",
    "    T_max= epochs-warmup_epo-2 \n",
    "    \n",
    "    seq_len = 90\n",
    "    img_size = 256\n",
    "    p_mixup = 0.5\n",
    "\n",
    "    lr=4e-5\n",
    "    min_lr=1e-7\n",
    "    # lr=23e-5\n",
    "    # min_lr=23e-6\n",
    "    weight_decay=0.02\n",
    "    dropout=0.1\n",
    "\n",
    "    gpu_parallel=False\n",
    "    n_early_stopping=8\n",
    "    debug=False\n",
    "    multihead=False\n",
    "    plane = 'ax_t2' # 'sag_t1', 'sag_t2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [i for i in timm.list_models(pretrained=True) if 'resnest50d' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pandas -q\n",
    "# !pip install scikit-learn -q\n",
    "# !pip install warmup-scheduler==0.3 -q\n",
    "# !pip install timm==0.9.7 -q\n",
    "# !pip install albumentations==1.3.1\n",
    "# !pip install opencv-python -q\n",
    "# !pip install segmentation_models_pytorch\n",
    "# !apt-get update && apt-get install ffmpeg libsm6 libxext6  -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35569/4272702869.py:44: DeprecationWarning: Please import `zoom` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.ndimage.interpolation import zoom\n"
     ]
    }
   ],
   "source": [
    "import sys; \n",
    "\n",
    "package_paths = [f'{libdir}pytorch-image-models-master']\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "\n",
    "import ast\n",
    "from glob import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from contextlib import contextmanager\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, StratifiedGroupKFold\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import timm\n",
    "import warnings\n",
    "import joblib\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import gc \n",
    "from torch.nn import DataParallel\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "\n",
    "if CFG.device == 'TPU':\n",
    "    !pip install -q pytorch-ignite\n",
    "    import ignite.distributed as idist\n",
    "elif CFG.device == 'GPU':\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()\n",
    "\n",
    "\n",
    "def torch_sigmoid(x): return (1 + (-x).exp()).reciprocal()\n",
    "\n",
    "\n",
    "class Custom_loss(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, temperature=0.0):\n",
    "        \"\"\"\n",
    "        Use max if temperature = 0\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.t = temperature\n",
    "        assert self.t >= 0\n",
    "    def __repr__(self):\n",
    "        return 'SevereLoss(t=%.1f)' % self.t\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0], 25, 3).transpose(1, 2)\n",
    "\n",
    "        y = y.reshape(y.shape[0], 25, 3).transpose(1, 2).argmax(1)\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          y_pred (Tensor[float]): logit             (batch_size, 3, 25)\n",
    "          y      (Tensor[int]):   true label index  (batch_size, 25)\n",
    "        \"\"\"\n",
    "        assert y_pred.size(0) == y.size(0)\n",
    "        assert y_pred.size(1) == 3 and y_pred.size(2) == 25\n",
    "        assert y.size(1) == 25\n",
    "        assert y.size(0) > 0\n",
    "        slices = [slice(0, 5), slice(5, 15), slice(15, 25)] \n",
    "\n",
    "        loss = F.cross_entropy(y_pred, y.long(), reduction='none')  # (batch_size, 25)\n",
    "\n",
    "        wloss_sums = []\n",
    "        for k, idx in enumerate(slices):\n",
    "            wloss_sums.append((loss[:, idx]).sum())\n",
    "        y_spinal_prob = y_pred[:, :, :5].softmax(dim=1)             # (batch_size, 3,  5)\n",
    "        y_max = torch.amax(y[:, :5] == 2, dim=1).to(y_pred.dtype)   # 0 or 1\n",
    "        if self.t > 0:\n",
    "            # Attention for the maximum value\n",
    "            attn = F.softmax(y_spinal_prob[:, 2, :] / self.t, dim=1)  # (batch_size, 5)\n",
    "\n",
    "            # Pick the sofmax among 5 severe=2 y_spinal_probs with attn\n",
    "            y_pred_max = (attn * y_spinal_prob[:, 2, :]).sum(dim=1)   # weighted average among 5 spinal columns \n",
    "        else:\n",
    "            # Exact max; this works too\n",
    "            y_pred_max = y_spinal_prob[:, 2, :].amax(dim=1)\n",
    "        loss_max = F.binary_cross_entropy(y_pred_max, y_max, reduction='none')\n",
    "        wloss_sums.append((loss_max).sum())\n",
    "\n",
    "        # See below about these numbers\n",
    "        loss = (wloss_sums[0] / 6.084050632911392 +\n",
    "                wloss_sums[1] / 12.962531645569621 + \n",
    "                wloss_sums[2] / 14.38632911392405# +\n",
    "                # wloss_sums[3] / 1.729113924050633\n",
    "               ) / (3 * y.size(0))\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "def comp_metric_score(y_true, y_pred, w1 = 1, w2 = 1, apply_sig = True):\n",
    "    y_pred = sig(y_pred)\n",
    "    y_pred[:, 1::3] *= w1\n",
    "    y_pred[:, 2::3] *= w2\n",
    "    for i in range(0, 75, 3):\n",
    "        y_pred[:, i:i+3] /= y_pred[:, i:i+3].sum(1)[:, None]\n",
    "    y_pred = torch.from_numpy(y_pred)\n",
    "    y_pred = (torch.log(y_pred)/(1-y_pred))\n",
    "\n",
    "\n",
    "    y = torch.from_numpy(y_true.copy())\n",
    "    \n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], 25, 3).transpose(1, 2)\n",
    "    y = y.reshape(y.shape[0], 25, 3).transpose(1, 2).argmax(1)\n",
    "    # 4 losses for the evaluation metric\n",
    "    loss4_sum = torch.zeros(4)\n",
    "    w_sum = torch.zeros(4)\n",
    "    slices = [slice(0, 5), slice(5, 15), slice(15, 25)]  # spinal, foraminal, subarticular\n",
    "\n",
    "    w = 2 ** y  # sample_weight w = (1, 2, 4) for y = 0, 1, 2 (batch_size, 25)\n",
    "\n",
    "    batch_size = y_pred.shape[0]\n",
    "\n",
    "    ce_loss = F.cross_entropy(y_pred, y.long(), reduction='none')  # (batch_size, 25)\n",
    "    for k, idx in enumerate(slices):\n",
    "        w_sum[k] += w[:, idx].sum()\n",
    "        loss4_sum[k] += (w[:, idx] * ce_loss[:, idx]).sum()\n",
    "    # Spinal max\n",
    "    y_spinal_prob = y_pred[:, :, :5].softmax(dim=1)            # (batch_size, 3,  5)\n",
    "    w_max = torch.amax(w[:, :5], dim=1)                        # (batch_size, )\n",
    "    y_max = torch.amax(y[:, :5] == 2, dim=1).to(torch.float)   # 0 or 1\n",
    "    y_pred_max = y_spinal_prob[:, 2, :].amax(dim=1)            # max in severe (class=2)\n",
    "    loss_max = F.binary_cross_entropy(y_pred_max, y_max, reduction='none')\n",
    "    loss4_sum[3] += (w_max * loss_max).sum()\n",
    "    w_sum[3] += w_max.sum()\n",
    "    # Average over spinal, foraminal, subarticular, and any_severe_spinal\n",
    "    score = (loss4_sum / w_sum).sum().item() / 4\n",
    "    return score\n",
    "\n",
    "class Custom_loss2(nn.Module):\n",
    "\n",
    "    def forward(self, p, t):\n",
    "        p = p.sigmoid().reshape(-1, 25, 3)\n",
    "        p[..., 1] *= 2\n",
    "        p[..., 2] *= 4\n",
    "        p /= p.sum(2)[:,:,None]\n",
    "        p = p.reshape(-1, 75)\n",
    "        return F.binary_cross_entropy(p, t)\n",
    "\n",
    "def comp_metric_score2(y_true, y_pred, w1 = 1, w2 = 1, apply_sig = True):\n",
    "    t = y_true.copy()\n",
    "    p = y_pred.copy()\n",
    "    if apply_sig:\n",
    "        p = sig(p)\n",
    "    p[:, 1::3] *= w1\n",
    "    p[:, 2::3] *= w2\n",
    "    for i in range(0, 75, 3):\n",
    "        p[:,i:i+3] /= p[:,i:i+3].sum(1)[:, None]\n",
    "    t_sp, p_sp = t[:, :15].reshape(-1, 3), p[:, :15].reshape(-1, 3)\n",
    "    t_ne, p_ne = t[:, 15:45].reshape(-1, 3), p[:, 15:45].reshape(-1, 3)\n",
    "    t_su, p_su = t[:, 45:].reshape(-1, 3), p[:, 45:].reshape(-1, 3)\n",
    "    t_sp_sev, p_sp_sev = t[:, :15][:, 2::3].max(1), p[:, :15][:, 2::3].max(1)\n",
    "    loss_sp = log_loss(t_sp, p_sp, sample_weight = t_sp[:,0] + 2*t_sp[:,1]+4*t_sp[:, 2])\n",
    "    loss_ne = log_loss(t_ne, p_ne, sample_weight = t_ne[:,0] + 2*t_ne[:,1]+4*t_ne[:, 2])\n",
    "    loss_su = log_loss(t_su, p_su, sample_weight = t_su[:,0] + 2*t_su[:,1]+4*t_su[:, 2])\n",
    "    loss_sp_sev = log_loss(t_sp_sev, p_sp_sev)\n",
    "    print(loss_sp, loss_ne, loss_su, loss_sp_sev)\n",
    "    loss = (loss_sp + loss_ne + loss_su + loss_sp_sev)/4\n",
    "    print('w1 =', w1, 'w2 =', w2, loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENV = 'kaggle'\n",
    "if CFG.device == 'TPU':\n",
    "    import os\n",
    "    VERSION = \"1.7\"\n",
    "    CP_V = \"36\" if ENV == \"colab\" else \"37\"\n",
    "    wheel = f\"torch_xla-{VERSION}-cp{CP_V}-cp{CP_V}m-linux_x86_64.whl\"\n",
    "    url = f\"https://storage.googleapis.com/tpu-pytorch/wheels/{wheel}\"\n",
    "    !pip3 -q install cloud-tpu-client==0.10 $url\n",
    "    os.system('export XLA_USE_BF16=1')\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "    CFG.lr = CFG.lr * CFG.nprocs\n",
    "    CFG.train_bs = CFG.train_bs // CFG.nprocs\n",
    "    device = xm.xla_device()\n",
    "    \n",
    "elif CFG.device == \"GPU\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        score = roc_auc_score(y_true[:,i], y_pred[:,i])\n",
    "        scores.append(score)\n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score, scores\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=outputdir+'stage2_train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "if not os.path.isdir(outputdir):\n",
    "    os.mkdir(outputdir)\n",
    "LOGGER = init_logger(outputdir+f'/stage2_train{CFG.suffix}.log')\n",
    "\n",
    "if CFG.device=='TPU' and CFG.nprocs==8:\n",
    "    loginfo = xm.master_print\n",
    "    cusprint = xm.master_print\n",
    "else:\n",
    "    loginfo = LOGGER.info\n",
    "    cusprint = print\n",
    "\n",
    "\n",
    "\n",
    "def get_timediff(time1,time2):\n",
    "    minute_,second_ = divmod(time2-time1,60)\n",
    "    return f\"{int(minute_):02d}:{int(second_):02d}\"  \n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb\n",
    "\n",
    "def load_dicom(path):\n",
    "    \"\"\"\n",
    "    This supports loading both regular and compressed JPEG images. \n",
    "    See the first sell with `pip install` commands for the necessary dependencies\n",
    "    \"\"\"\n",
    "    img = dicom.dcmread(path)\n",
    "    img.PhotometricInterpretation = 'YBR_FULL'\n",
    "    data = img.pixel_array\n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    # data = (data * 255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, csv, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2, targets, mode, meta_features, in_chans, transform=None):\n",
    "\n",
    "        self.csv = csv.reset_index(drop=True)\n",
    "        self.ser_dict_sag_t1 = ser_dict_sag_t1\n",
    "        self.ser_dict_sag_t2 = ser_dict_sag_t2\n",
    "        self.ser_dict_ax_t2 = ser_dict_ax_t2\n",
    "        self.targets = targets\n",
    "        self.mode = mode\n",
    "        self.use_meta = meta_features is not None\n",
    "        self.meta_features = meta_features\n",
    "        self.transform = transform\n",
    "        self.in_chans = in_chans\n",
    "        \n",
    "        self.aug_tr = v2.RandomRotation(\n",
    "                            degrees = (-45, 45),\n",
    "                            interpolation = torchvision.transforms.InterpolationMode.BILINEAR,\n",
    "                            expand = False,\n",
    "                            center = None,\n",
    "                            fill = 0\n",
    "                        )\n",
    "        self.aug_sj = v2.ScaleJitter(\n",
    "                        target_size = [CFG.img_size, CFG.img_size],\n",
    "                        scale_range = (0.8, 1.2),\n",
    "                        interpolation = torchvision.transforms.InterpolationMode.BILINEAR,\n",
    "                        antialias = True)\n",
    "        self.aug_rc = v2.RandomCrop(\n",
    "                            size = [CFG.img_size, CFG.img_size],\n",
    "                            pad_if_needed = True,\n",
    "                            fill = 0,\n",
    "                            padding_mode = 'constant'\n",
    "                        )\n",
    "        self.aug_hf = v2.RandomHorizontalFlip(0.5)\n",
    "        self.aug_vf = v2.RandomVerticalFlip(0.5)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = self.csv.iloc[index]\n",
    "        \n",
    "        plane = CFG.plane\n",
    "        \n",
    "\n",
    "        study_id = int(row.study_id)\n",
    "                \n",
    "        if plane in ['sag_t1', 'sag_t2'] and study_id not in self.ser_dict_sag_t1.keys():\n",
    "            if self.mode == 'train':\n",
    "                serie_id = np.random.choice(self.ser_dict_sag_t2[study_id])\n",
    "            else:\n",
    "                serie_id = self.ser_dict_sag_t2[study_id][-1]\n",
    "        elif plane in ['sag_t1', 'sag_t2'] and study_id not in self.ser_dict_sag_t2.keys():\n",
    "            if self.mode == 'train':\n",
    "                serie_id = np.random.choice(self.ser_dict_sag_t1[study_id])\n",
    "            else:\n",
    "                serie_id = self.ser_dict_sag_t1[study_id][-1]\n",
    "        else:\n",
    "            if plane == 'sag_t1':\n",
    "                if self.mode == 'train':\n",
    "                    serie_id = np.random.choice(self.ser_dict_sag_t1[study_id])\n",
    "                else:\n",
    "                    serie_id = self.ser_dict_sag_t1[study_id][-1]\n",
    "            elif plane == 'sag_t2':\n",
    "                if self.mode == 'train':\n",
    "                    serie_id = np.random.choice(self.ser_dict_sag_t2[study_id])\n",
    "                else:\n",
    "                    serie_id = self.ser_dict_sag_t2[study_id][-1]\n",
    "            else:\n",
    "                if self.mode == 'train':\n",
    "                    serie_id = np.random.choice(self.ser_dict_ax_t2[study_id])\n",
    "                else:\n",
    "                    serie_id = self.ser_dict_ax_t2[study_id][-1]\n",
    "        if self.mode == 'train':\n",
    "            serie_id_ax_t2 = np.random.choice(self.ser_dict_ax_t2[study_id])\n",
    "        else:\n",
    "            serie_id_ax_t2 = self.ser_dict_ax_t2[study_id][-1]\n",
    "        fp = f'/dev/shm/preprocessed/{study_id}_{serie_id}.npy'\n",
    "        image = np.load(fp)\n",
    "\n",
    "\n",
    "        image = torch.from_numpy(image).float()/255\n",
    "        image = F.interpolate(\n",
    "                 image.unsqueeze(0).unsqueeze(0),\n",
    "                 size=[CFG.seq_len, CFG.img_size, CFG.img_size],\n",
    "                 mode='trilinear'\n",
    "             ).squeeze(0).squeeze(0)\n",
    "\n",
    "        if (self.mode == 'train') and np.random.rand()<0.5:\n",
    "            image = self.aug_tr(image)\n",
    "            image = self.aug_sj(image)\n",
    "            image = self.aug_rc(image)\n",
    "\n",
    "        l_img = image.shape[0]\n",
    "        if (self.mode == 'train') and np.random.rand()<0.5:\n",
    "            inds = np.random.choice(np.arange(l_img), CFG.seq_len)\n",
    "            inds.sort()\n",
    "            image = image[inds]\n",
    "\n",
    "        image = image.numpy()\n",
    "        tar = torch.tensor(row[self.targets]).float()\n",
    "        if self.mode == 'train' and np.random.uniform()<=0.5:\n",
    "            tar = torch.cat([tar[:15], tar[30:45], tar[15:30], tar[60:75], tar[45:60]])\n",
    "            image = image[:, ::-1]\n",
    "\n",
    "\n",
    "        # transform\n",
    "        if self.transform:\n",
    "            \n",
    "            image = np.transpose(image, (1, 2, 0))\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "            image = torch.from_numpy(image)\n",
    "\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return study_id, image\n",
    "        else:\n",
    "            return study_id, image, tar\n",
    "\n",
    "\n",
    "\n",
    "def get_transforms(*, data):\n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "    albumentations.Resize(CFG.img_size, CFG.img_size),\n",
    "    albumentations.Perspective(p=0.5),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.VerticalFlip(p=0.5),\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.RandomBrightness(limit=0.1, p=0.7),\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, border_mode=4, p=0.7),\n",
    "\n",
    "    albumentations.OneOf([\n",
    "        albumentations.MotionBlur(blur_limit=3),\n",
    "        albumentations.MedianBlur(blur_limit=3),\n",
    "        albumentations.GaussianBlur(blur_limit=3),\n",
    "        albumentations.GaussNoise(var_limit=(3.0, 9.0)),\n",
    "    ], p=0.5),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.OpticalDistortion(distort_limit=1.),\n",
    "        albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "    ], p=0.5),\n",
    "\n",
    "    albumentations.Cutout(max_h_size=int(CFG.img_size * 0.5), max_w_size=int(CFG.img_size * 0.5), num_holes=1, p=0.5),\n",
    "            ])\n",
    "    elif data == 'light_train':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.img_size, CFG.img_size),\n",
    "            A.Perspective(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, p=0.75),\n",
    "            A.OneOf(\n",
    "                [\n",
    "                    A.RandomGamma(p=1),\n",
    "                    A.RandomBrightnessContrast(contrast_limit=0.2, brightness_limit=0.0, p=1),\n",
    "                    A.RandomBrightnessContrast(contrast_limit=0.0, brightness_limit=0.2, p=1),\n",
    "                ],\n",
    "                p=0.5,\n",
    "            ),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(p = 1),\n",
    "                A.GaussianBlur(p = 1),\n",
    "                A.GaussNoise(p = 1),\n",
    "                ], p=0.5),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.05, p=0.5),\n",
    "            ], p=1.0)\n",
    "    elif data == 'valid':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.img_size, CFG.img_size),\n",
    "\n",
    "        ], p=1.0)\n",
    "\n",
    "\n",
    "\n",
    "def get_df():\n",
    "\n",
    "    df = pd.read_csv('train.csv')\n",
    "\n",
    "    for c in conditions:\n",
    "        for l in levels:\n",
    "            for s in severity:\n",
    "                df[c + '_' + l + '_' + s] =  (df[c + '_' + l] == s).astype(int)\n",
    "    df = df[['study_id']+CFG.target_cols]\n",
    "    tr_ser_desc = pd.read_csv('train_series_descriptions.csv')\n",
    "    ser_dict_sag_t1 = tr_ser_desc[tr_ser_desc['series_description']=='Sagittal T1'][['study_id', 'series_id']].groupby('study_id').apply(lambda df:df.series_id.tolist()).to_dict()\n",
    "    ser_dict_sag_t2 = tr_ser_desc[tr_ser_desc['series_description']=='Sagittal T2/STIR'][['study_id', 'series_id']].groupby('study_id').apply(lambda df:df.series_id.tolist()).to_dict()\n",
    "    ser_dict_ax_t2 = tr_ser_desc[tr_ser_desc['series_description']=='Axial T2'][['study_id', 'series_id']].groupby('study_id').apply(lambda df:df.series_id.tolist()).to_dict()\n",
    "    print(len(df), len(ser_dict_sag_t1), len(ser_dict_sag_t2), len(ser_dict_ax_t2))\n",
    "\n",
    "    skf = StratifiedGroupKFold(n_splits = CFG.fold_num)\n",
    "    df['fold'] = -1\n",
    "    for i, (train_inds, val_inds) in enumerate(skf.split(df, df[CFG.target_cols[-1]], df['study_id'])):\n",
    "        df.loc[val_inds, 'fold'] = i\n",
    "\n",
    "    return df, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pylab import rcParams\n",
    "# dataset_show = TrainDataset(\n",
    "#     train_df,\n",
    "#     transform=get_transforms(data='light_train') # None, get_transforms(data='check')\n",
    "#     )\n",
    "# rcParams['figure.figsize'] = 30,20\n",
    "# for i in range(2):\n",
    "#     f, axarr = plt.subplots(1,5)\n",
    "#     idx = np.random.randint(0, len(dataset_show))\n",
    "#     img, label= dataset_show[idx]\n",
    "#     # axarr[p].imshow(img) # transform=None\n",
    "#     axarr[0].imshow(img[0]); plt.axis('OFF');\n",
    "#     axarr[1].imshow(img[1]); plt.axis('OFF');\n",
    "#     axarr[2].imshow(img[2]); plt.axis('OFF');\n",
    "#     axarr[3].imshow(img[3]); plt.axis('OFF');\n",
    "#     axarr[4].imshow(img[4]); plt.axis('OFF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from itertools import repeat\n",
    "\n",
    "class SpatialDropout(nn.Module):\n",
    "    def __init__(self, drop=0.5):\n",
    "        super(SpatialDropout, self).__init__()\n",
    "        self.drop = drop\n",
    "        \n",
    "    def forward(self, inputs, noise_shape=None):\n",
    "        \"\"\"\n",
    "        @param: inputs, tensor\n",
    "        @param: noise_shape, tuple\n",
    "        \"\"\"\n",
    "        outputs = inputs.clone()\n",
    "        if noise_shape is None:\n",
    "            noise_shape = (inputs.shape[0], *repeat(1, inputs.dim()-2), inputs.shape[-1]) \n",
    "        \n",
    "        self.noise_shape = noise_shape\n",
    "        if not self.training or self.drop == 0:\n",
    "            return inputs\n",
    "        else:\n",
    "            noises = self._make_noises(inputs)\n",
    "            if self.drop == 1:\n",
    "                noises.fill_(0.0)\n",
    "            else:\n",
    "                noises.bernoulli_(1 - self.drop).div_(1 - self.drop)\n",
    "            noises = noises.expand_as(inputs)    \n",
    "            outputs.mul_(noises)\n",
    "            return outputs\n",
    "            \n",
    "    def _make_noises(self, inputs):\n",
    "        return inputs.new().resize_(self.noise_shape)\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Dict, Optional\n",
    " \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "\n",
    "class MLPAttentionNetwork(nn.Module):\n",
    " \n",
    "    def __init__(self, hidden_dim, attention_dim=None):\n",
    "        super(MLPAttentionNetwork, self).__init__()\n",
    " \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        if self.attention_dim is None:\n",
    "            self.attention_dim = self.hidden_dim\n",
    "        # W * x + b\n",
    "        self.proj_w = nn.Linear(self.hidden_dim, self.attention_dim, bias=True)\n",
    "        # v.T\n",
    "        self.proj_v = nn.Linear(self.attention_dim, 1, bias=False)\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: seq_len, batch_size, hidden_dim\n",
    "        :return: batch_size * seq_len, batch_size * hidden_dim\n",
    "        \"\"\"\n",
    "        # print(f\"x shape:{x.shape}\")\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        # flat_inputs = x.reshape(-1, self.hidden_dim) # (batch_size*seq_len, hidden_dim)\n",
    "        # print(f\"flat_inputs shape:{flat_inputs.shape}\")\n",
    "        \n",
    "        H = torch.tanh(self.proj_w(x)) # (batch_size, seq_len, hidden_dim)\n",
    "        # print(f\"H shape:{H.shape}\")\n",
    "        \n",
    "        att_scores = torch.softmax(self.proj_v(H),axis=1) # (batch_size, seq_len)\n",
    "        # print(f\"att_scores shape:{att_scores.shape}\")\n",
    "        \n",
    "        attn_x = (x * att_scores).sum(1) # (batch_size, hidden_dim)\n",
    "        # print(f\"attn_x shape:{attn_x.shape}\")\n",
    "        return attn_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6, p_trainable=False):\n",
    "        super(GeM, self).__init__()\n",
    "        if p_trainable:\n",
    "            self.p = nn.parameter.Parameter(torch.ones(1) * p)\n",
    "        else:\n",
    "            self.p = p\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        ret = gem(x, p=self.p, eps=self.eps)\n",
    "        return ret\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            self.__class__.__name__\n",
    "            + \"(\"\n",
    "            + \"p=\"\n",
    "            + \"{:.4f}\".format(self.p.data.tolist()[0])\n",
    "            + \", \"\n",
    "            + \"eps=\"\n",
    "            + str(self.eps)\n",
    "            + \")\"\n",
    "        )\n",
    "    \n",
    "    \n",
    "def drop_path(x, drop_prob: float = 0., training: bool = False, scale_by_keep: bool = True):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
    "\n",
    "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
    "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
    "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
    "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
    "    'survival rate' as the argument.\n",
    "\n",
    "    \"\"\"\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = x.new_empty(shape).bernoulli_(keep_prob)\n",
    "    if keep_prob > 0.0 and scale_by_keep:\n",
    "        random_tensor.div_(keep_prob)\n",
    "    return x * random_tensor\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob=None, scale_by_keep=True):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.scale_by_keep = scale_by_keep\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class RSNAClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, hidden_dim=256, seq_len=CFG.seq_len, pretrained=False, softmax = False):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.model = timm.create_model(model_arch, in_chans=3, pretrained=pretrained)\n",
    "        self.softmax = softmax\n",
    "\n",
    "        if 'efficientnet' in CFG.model_arch:\n",
    "            cnn_feature = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Identity()\n",
    "        elif \"res\" in CFG.model_arch or 1:\n",
    "            cnn_feature = self.model.fc.in_features\n",
    "            self.model.global_pool = nn.Identity()\n",
    "            self.model.fc = nn.Identity()\n",
    "            self.pooling = nn.AdaptiveAvgPool2d(1)#GeM(p_trainable=False)\n",
    "        \n",
    "        elif CFG.model_arch == \"convnextv2_tiny\":\n",
    "            cnn_feature = 1000\n",
    "            self.model.global_pool = nn.Identity()\n",
    "            self.pooling = nn.AdaptiveAvgPool2d(1)#GeM(p_trainable=True)\n",
    "\n",
    "        self.spatialdropout = SpatialDropout(CFG.dropout)\n",
    "        self.gru = nn.GRU(cnn_feature, cnn_feature//2, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.mlp_attention_layers = nn.ModuleList([MLPAttentionNetwork(cnn_feature) for _ in range(5)])\n",
    "\n",
    "        self.logits = nn.ModuleList([nn.Sequential(\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(cnn_feature, 15),\n",
    "                ) for _ in range(5)])\n",
    "\n",
    "    def forward(self, x): # (B, seq_len, H, W)\n",
    "        bs = x.size(0)\n",
    "        \n",
    "        x = x.reshape(bs*self.seq_len//3, 3, x.size(2), x.size(3)) # (B*seq_len, 1, H, W)\n",
    "        features = self.model(x)\n",
    "        if \"res\" in CFG.model_arch:\n",
    "            features = self.pooling(features).view(bs*self.seq_len//3, -1) # (B*seq_len, cnn_feature)\n",
    "        features = self.spatialdropout(features)                # (B*seq_len, cnn_feature)\n",
    "        features = features.reshape(bs, self.seq_len//3, -1)       # (B, seq_len, cnn_feature)\n",
    "        features, _ = self.gru(features)                        # (B, seq_len, hidden_dim*2)\n",
    "        preds = []\n",
    "        for att_layer, logit in zip(self.mlp_attention_layers, self.logits):\n",
    "            p = att_layer(features)\n",
    "            p = logit(p)\n",
    "            preds.append(p)\n",
    "        preds = torch.cat(preds, -1)\n",
    "        if self.softmax:\n",
    "            preds = torch.cat([preds[:, i:i+3].softmax(1) for i in range(0, 75, 3)], -1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = RSNAClassifier(CFG.model_arch, hidden_dim=128, seq_len=CFG.seq_len, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_activation(activ_name: str=\"relu\"):\n",
    "    \"\"\"\"\"\"\n",
    "    act_dict = {\n",
    "        \"relu\": nn.ReLU(inplace=True),\n",
    "        \"tanh\": nn.Tanh(),\n",
    "        \"sigmoid\": nn.Sigmoid(),\n",
    "        \"identity\": nn.Identity()}\n",
    "    if activ_name in act_dict:\n",
    "        return act_dict[activ_name]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class Conv2dBNActiv(nn.Module):\n",
    "    \"\"\"Conv2d -> (BN ->) -> Activation\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_channels, out_channels,\n",
    "        kernel_size, stride, padding,\n",
    "        bias=False, use_bn=True, activ=\"relu\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(Conv2dBNActiv, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size, stride, padding, bias=bias))\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "        layers.append(get_activation(activ))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        return self.layers(x)\n",
    "        \n",
    "    \n",
    "class SpatialAttentionBlock(nn.Module):\n",
    "    \"\"\"Spatial Attention for (C, H, W) feature maps\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_channels,\n",
    "        out_channels_list,\n",
    "    ):\n",
    "        \"\"\"Initialize\"\"\"\n",
    "        super(SpatialAttentionBlock, self).__init__()\n",
    "        self.n_layers = len(out_channels_list)\n",
    "        channels_list = [in_channels] + out_channels_list\n",
    "        assert self.n_layers > 0\n",
    "        assert channels_list[-1] == 1\n",
    "        \n",
    "        for i in range(self.n_layers - 1):\n",
    "            in_chs, out_chs = channels_list[i: i + 2]\n",
    "            layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"relu\")\n",
    "            setattr(self, f\"conv{i + 1}\", layer)\n",
    "            \n",
    "        in_chs, out_chs = channels_list[-2:]\n",
    "        layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"sigmoid\")\n",
    "        setattr(self, f\"conv{self.n_layers}\", layer)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        h = x\n",
    "        for i in range(self.n_layers):\n",
    "            h = getattr(self, f\"conv{i + 1}\")(h)\n",
    "            \n",
    "        h = h * x\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadResNet200D(nn.Module):\n",
    "    def __init__(self, out_dims_head=[3, 4, 3, 1],  pretrained=False):\n",
    "        self.base_name = \"resnet200d_320\"\n",
    "        self.n_heads = len(out_dims_head)\n",
    "        super(MultiHeadResNet200D, self).__init__()\n",
    "        \n",
    "        # # load base model\n",
    "        base_model = timm.create_model(self.base_name, num_classes=sum(out_dims_head), pretrained=False)\n",
    "        in_features = base_model.num_features\n",
    "        \n",
    "        if pretrained:\n",
    "            pretrained_model_path = CFG.student\n",
    "            state_dict = dict()\n",
    "            for k, v in torch.load(pretrained_model_path, map_location='cpu')[\"model\"].items():\n",
    "                if k[:6] == \"model.\":\n",
    "                    k = k.replace(\"model.\", \"\")\n",
    "                state_dict[k] = v\n",
    "            base_model.load_state_dict(state_dict)\n",
    "        \n",
    "        # # remove global pooling and head classifier\n",
    "        base_model.reset_classifier(0, '')\n",
    "        \n",
    "        # # Shared CNN Bacbone\n",
    "        self.backbone = base_model\n",
    "        \n",
    "        # # Multi Heads.\n",
    "        for i, out_dim in enumerate(out_dims_head):\n",
    "            layer_name = f\"head_{i}\"\n",
    "            layer = nn.Sequential(\n",
    "                SpatialAttentionBlock(in_features, [64, 32, 16, 1]),\n",
    "                nn.AdaptiveAvgPool2d(output_size=1),\n",
    "                nn.Flatten(start_dim=1),\n",
    "                nn.Linear(in_features, in_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(in_features, out_dim))\n",
    "            setattr(self, layer_name, layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x)\n",
    "        hs = [getattr(self, f\"head_{i}\")(h) for i in range(self.n_heads)]\n",
    "        y = torch.cat(hs, axis=1)\n",
    "        return None, None, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup(input, truth, clip=[0, 1]):\n",
    "    indices = torch.randperm(input.size(0))\n",
    "    shuffled_input = input[indices]\n",
    "    shuffled_labels = truth[indices]\n",
    "\n",
    "    lam = np.random.uniform(clip[0], clip[1])\n",
    "    input = input * lam + shuffled_input * (1 - lam)\n",
    "    return input, truth, shuffled_labels, lam\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    if CFG.device == 'GPU':\n",
    "        scaler = GradScaler()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    for step, (study_id, images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        batch_size = labels.size(0)\n",
    "        \n",
    "        do_mixup = False\n",
    "        if random.random() < CFG.p_mixup:\n",
    "            do_mixup = True\n",
    "            images, labels, labels_mix, lam = mixup(images, labels)\n",
    "\n",
    "        if CFG.device == 'GPU':\n",
    "            # with autocast():\n",
    "            y_preds = model(images)\n",
    "            y_preds = y_preds.squeeze(1)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            if do_mixup:\n",
    "                loss11 = criterion(y_preds, labels_mix)\n",
    "                loss = loss * lam  + loss11 * (1 - lam)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.accum_iter > 1:\n",
    "                loss = loss / CFG.accum_iter\n",
    "            scaler.scale(loss).backward()\n",
    "            grad_norm = 0 # torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.accum_iter == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "        elif CFG.device == 'TPU':\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.accum_iter > 1:\n",
    "                loss = loss / CFG.accum_iter\n",
    "            loss.backward()\n",
    "            grad_norm = 0 # torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.accum_iter == 0:\n",
    "                xm.optimizer_step(optimizer, barrier=True)\n",
    "                optimizer.zero_grad()\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            cusprint('Epoch: [{0}][{1}/{2}] '\n",
    "                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                'Elapsed {remain:s} '\n",
    "                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                'Grad: {grad_norm:.4f}  '\n",
    "                'LR: {lr:.7f}  '\n",
    "                .format(\n",
    "                epoch, step, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses,\n",
    "                remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                grad_norm=grad_norm,\n",
    "                lr=optimizer.param_groups[0][\"lr\"],\n",
    "                ))\n",
    "        if(step == 0):print(loss)\n",
    "\n",
    "    return losses.avg, optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tta(images, nbr):\n",
    "    return torch.cat([images[:,nbr:,...], torch.cat(nbr*[images[:,-1:,...]], 1)], 1)\n",
    "\n",
    "\n",
    "def evaluate(y_preds, y_true, www = 1):\n",
    "    y_pred = torch.from_numpy(y_preds.copy())\n",
    "    y = torch.from_numpy(y_true.copy())\n",
    "    # loss0 = criterion(y_pred, y)\n",
    "    \n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], 25, 3).transpose(1, 2).softmax(dim=1)\n",
    "    if www==2:\n",
    "        y_pred[:, 1] *= 2\n",
    "        y_pred[:, 2] *= 4\n",
    "        y_pred /= y_pred.sum(1)[:, None]\n",
    "    y_pred = (torch.log(y_pred)/(1-y_pred))\n",
    "    y = y.reshape(y.shape[0], 25, 3).transpose(1, 2).argmax(1)\n",
    "\n",
    "    n_sum = 0\n",
    "    # loss0_sum = 0.0  # loss for the criterion\n",
    "    \n",
    "    # 4 losses for the evaluation metric\n",
    "    loss4_sum = torch.zeros(4)\n",
    "    w_sum = torch.zeros(4)\n",
    "    slices = [slice(0, 5), slice(5, 15), slice(15, 25)]  # spinal, foraminal, subarticular\n",
    "\n",
    "    w = 2 ** y  # sample_weight w = (1, 2, 4) for y = 0, 1, 2 (batch_size, 25)\n",
    "\n",
    "    batch_size = y_pred.shape[0]\n",
    "\n",
    "    n_sum += batch_size\n",
    "    # loss0_sum += loss0.item() * batch_size\n",
    "\n",
    "    # Compute score\n",
    "    # - weighted loss for spinal, foraminal, subarticular\n",
    "    # - binary cross entropy for maximum spinal severe\n",
    "    ce_loss = F.cross_entropy(y_pred, y.long(), reduction='none')  # (batch_size, 25)\n",
    "    for k, idx in enumerate(slices):\n",
    "        w_sum[k] += w[:, idx].sum()\n",
    "        loss4_sum[k] += (w[:, idx] * ce_loss[:, idx]).sum()\n",
    "    # Spinal max\n",
    "    y_spinal_prob = y_pred[:, :, :5].softmax(dim=1)            # (batch_size, 3,  5)\n",
    "    w_max = torch.amax(w[:, :5], dim=1)                        # (batch_size, )\n",
    "    y_max = torch.amax(y[:, :5] == 2, dim=1).to(torch.float)   # 0 or 1\n",
    "    y_pred_max = y_spinal_prob[:, 2, :].amax(dim=1)            # max in severe (class=2)\n",
    "\n",
    "    loss_max = F.binary_cross_entropy(y_pred_max, y_max, reduction='none')\n",
    "    loss4_sum[3] += (w_max * loss_max).sum()\n",
    "    w_sum[3] += w_max.sum()\n",
    "    # Average over spinal, foraminal, subarticular, and any_severe_spinal\n",
    "    score = (loss4_sum / w_sum).sum().item() / 4\n",
    "    print('weight =', www, 'evaluation score =', score)\n",
    "\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "def valid_one_epoch(valid_loader, model, criterion, device, softmax = False):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    trues = []\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (study_id, images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)#(model(images) + model(tta(images, 1)))/2\n",
    "            y_preds = y_preds.squeeze(1)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        # y_preds = y_preds.reshape(-1, 25, 3).softmax(dim=2).reshape(-1, 75)\n",
    "        trues.append(labels.to('cpu').numpy())\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            cusprint('EVAL: [{0}/{1}] '\n",
    "                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                'Elapsed {remain:s} '\n",
    "                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                .format(\n",
    "                step, len(valid_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses,\n",
    "                remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                ))\n",
    "\n",
    "    trues = np.concatenate(trues)\n",
    "    predictions = np.concatenate(preds)\n",
    "    sc = evaluate(predictions, trues, www = 1)\n",
    "    sc = evaluate(predictions, trues, www = 2)\n",
    "    print(f\"trues.shape: {trues.shape}\")\n",
    "    print(f\"predictions.shape: {predictions.shape}\")\n",
    "    if softmax:\n",
    "        score = nn.BCELoss()(torch.from_numpy(predictions).type(torch.float32), torch.from_numpy(trues).type(torch.float32))\n",
    "        score2 = comp_metric_score(trues, predictions, apply_sig = False)\n",
    "        score3 = comp_metric_score(trues, predictions, w1 = 2, w2 = 4, apply_sig = False)\n",
    "    else:\n",
    "        score = nn.BCEWithLogitsLoss()(torch.from_numpy(predictions).type(torch.float32), torch.from_numpy(trues).type(torch.float32))\n",
    "        score2 = comp_metric_score(trues, predictions, apply_sig = True)\n",
    "        score3 = comp_metric_score(trues, predictions, w1 = 2, w2 = 4, apply_sig = True)\n",
    "        _ = comp_metric_score2(trues, predictions, w1 = 1, w2 = 1, apply_sig = True)\n",
    "        _ = comp_metric_score2(trues, predictions, w1 = 2, w2 = 4, apply_sig = True)\n",
    "\n",
    "    \n",
    "    return losses.avg, predictions, trues, score, score2, score3, sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss & optimizer & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GradualWarmupSchedulerV3(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV3, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(df, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2, fold):\n",
    "    loginfo(f\"========== fold: {fold} training ==========\")\n",
    "    if CFG.plane == 'sag_t2':\n",
    "        df = df[df['study_id'].isin(ser_dict_sag_t2.keys())]\n",
    "    elif CFG.plane == 'sag_t1':\n",
    "        df = df[df['study_id'].isin(ser_dict_sag_t1.keys())]\n",
    "    else:\n",
    "        df = df[df['study_id'].isin(ser_dict_ax_t2.keys())]\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = df[df['fold']!=fold].reset_index(drop=True)################################################\"[:700]\n",
    "    valid_folds = df[df['fold']==fold].reset_index(drop=True)\n",
    "    \n",
    "    softmax = False\n",
    "    if CFG.loss_fn == \"BCEWithLogitsLoss\":\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    elif CFG.loss_fn == 'Custom_loss':\n",
    "        cust = Custom_loss()\n",
    "        cust2 = nn.BCEWithLogitsLoss()\n",
    "        def criterion(y_pred, y):\n",
    "            return 0.75*cust(y_pred, y) + 0.25*cust2(y_pred, y)\n",
    "        # softmax = True\n",
    "    elif(CFG.loss_fn == 'FocalLoss'):\n",
    "        criterion = FocalLoss()\n",
    "\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2, CFG.target_cols, 'train', None, CFG.seq_len, transform=get_transforms(data='light_train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2, CFG.target_cols, 'valid', None, CFG.seq_len, transform=get_transforms(data='valid'))\n",
    "    if CFG.device == 'GPU':\n",
    "        # sampler_train = torch.utils.data.RandomSampler(ds_train_len)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs, shuffle=True, num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    elif CFG.device == 'TPU':\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=True)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.train_bs, sampler=train_sampler, drop_last=True, num_workers=CFG.num_workers)\n",
    "        valid_sampler = torch.utils.data.distributed.DistributedSampler(valid_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=False)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=CFG.valid_bs, sampler=valid_sampler, drop_last=False, num_workers=CFG.num_workers)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer & scheduler & loss\n",
    "    # ====================================================\n",
    "    # not checkpoint\n",
    "\n",
    "    if CFG.multihead:\n",
    "        model = MultiHeadResNet200D([3, 4, 3, 1], True)\n",
    "    else:\n",
    "        model = RSNAClassifier(CFG.model_arch, hidden_dim=256, seq_len=CFG.seq_len, pretrained=True, softmax = softmax)\n",
    "\n",
    "        \n",
    "    if CFG.gpu_parallel:    \n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        model = DataParallel(model, device_ids=range(num_gpu))\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    # optimizer\n",
    "    if CFG.optimizer == \"AdamW\":\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            optimizer = AdamW(model.parameters(), lr=CFG.lr/CFG.warmup_factor, weight_decay=CFG.weight_decay) \n",
    "        else:\n",
    "            optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    if CFG.optimizer == \"Adam\":\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            optimizer = Adam(model.parameters(), lr=CFG.lr/CFG.warmup_factor, weight_decay=CFG.weight_decay) \n",
    "        else:\n",
    "            optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    if CFG.optimizer == \"SGD\":\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            optimizer = SGD(model.parameters(), lr=CFG.lr/CFG.warmup_factor, weight_decay=CFG.weight_decay) \n",
    "        else:\n",
    "            optimizer = SGD(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    # scheduler,\n",
    "    if CFG.scheduler=='ReduceLROnPlateau':\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "    elif CFG.scheduler=='CosineAnnealingLR':\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "    elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "\n",
    "    scheduler_warmup = GradualWarmupSchedulerV3(optimizer, multiplier=CFG.warmup_factor, total_epoch=CFG.warmup_epo, after_scheduler=scheduler)\n",
    "\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    valid_acc_max=0; valid_loss_min=float(\"inf\")\n",
    "    valid_acc_max_cnt=0; valid_loss_min_cnt=0;\n",
    "    best_acc_epoch=0;\n",
    "\n",
    "\n",
    "    best_score = 10000\n",
    "\n",
    "    shift_epoch = CFG.shift_epoch#(3*CFG.epochs)//4\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        if epoch == shift_epoch:\n",
    "            model_ = RSNAClassifier(CFG.model_arch, hidden_dim=256, seq_len=CFG.seq_len, pretrained=True, softmax = True)\n",
    "            model_.to(device)\n",
    "            model_.load_state_dict(model.state_dict())\n",
    "            model = model_\n",
    "            criterion = Custom_loss()\n",
    "            softmax = True\n",
    "            optimizer_ = AdamW(model.parameters(), lr=CFG.lr/CFG.warmup_factor, weight_decay=CFG.weight_decay) \n",
    "            optimizer_.load_state_dict(optimizer.state_dict())\n",
    "            optimizer = optimizer_\n",
    "\n",
    "        loginfo(f\"***** Epoch {epoch} *****\")\n",
    "\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            loginfo(f\"schwarmup_last_epoch:{scheduler_warmup.last_epoch}, schwarmup_lr:{scheduler_warmup.get_last_lr()[0]}\")\n",
    "        if CFG.scheduler=='CosineAnnealingLR':\n",
    "            loginfo(f\"scheduler_last_epoch:{scheduler.last_epoch}, scheduler_lr:{scheduler.get_last_lr()[0]}\")\n",
    "        loginfo(f\"optimizer_lr:{optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        if(epoch>=CFG.min_epoch):\n",
    "            avg_loss, cur_lr = train_one_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device) # train\n",
    "        else:\n",
    "            avg_loss, cur_lr = -1, -1\n",
    "            model.load_state_dict(torch.load(outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}.pth')['model'])\n",
    "        avg_val_loss, preds, trues, score, score2, score3, score4 = valid_one_epoch(valid_loader, model, criterion, device, softmax = softmax) # valid\n",
    "\n",
    "        # scoring\n",
    "        elapsed = time.time() - start_time \n",
    "\n",
    "        loginfo(f'Epoch {epoch} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        loginfo(f'Epoch {epoch} - avg_val_loss: {avg_val_loss:.4f} - avg_val_bce: {score:.4f} - avg_val_comp_metric : {score2:.4f} - w_avg_val_comp_metric : {score3:.4f}')\n",
    "\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            scheduler_warmup.step()\n",
    "        elif CFG.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif CFG.scheduler in [\"CosineAnnealingLR\", \"CosineAnnealingWarmRestarts\"]:\n",
    "            scheduler.step()\n",
    "\n",
    "        if best_score>score4:\n",
    "            best_score = score4\n",
    "            np.save(outputdir+f'/{CFG.model_arch}_{CFG.suffix}__fold{fold}_preds.npy', preds)\n",
    "            np.save(outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_trues.npy', trues)\n",
    "            torch.save({'model': model.state_dict()}, outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}.pth')\n",
    "\n",
    "    return preds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    oof_df = pd.DataFrame()\n",
    "    oof_list = []\n",
    "    train_df, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2 = get_df()\n",
    "    for fold in CFG.fold_list:\n",
    "        preds, trues = train_loop(train_df, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2, fold)\n",
    "        oof_list.append([preds, trues])\n",
    "    return oof_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "1975 1973 1974 1975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "***** Epoch 0 *****\n",
      "schwarmup_last_epoch:0, schwarmup_lr:4.000000000000001e-06\n",
      "scheduler_last_epoch:0, scheduler_lr:4.000000000000001e-06\n",
      "optimizer_lr:4.000000000000001e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/371] Data 1.577 (1.577) Elapsed 0m 6s (remain 39m 52s) Loss: 0.7837(0.7837) Grad: 0.0000  LR: 0.0000040  \n",
      "tensor(0.7837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [0][100/371] Data 0.000 (0.035) Elapsed 0m 41s (remain 1m 50s) Loss: 0.5367(0.6327) Grad: 0.0000  LR: 0.0000040  \n",
      "Epoch: [0][200/371] Data 0.000 (0.040) Elapsed 1m 18s (remain 1m 6s) Loss: 0.3227(0.5501) Grad: 0.0000  LR: 0.0000040  \n",
      "Epoch: [0][300/371] Data 0.000 (0.042) Elapsed 1m 56s (remain 0m 27s) Loss: 0.3276(0.5093) Grad: 0.0000  LR: 0.0000040  \n",
      "Epoch: [0][370/371] Data 0.000 (0.040) Elapsed 2m 23s (remain 0m 0s) Loss: 0.2368(0.4899) Grad: 0.0000  LR: 0.0000040  \n",
      "EVAL: [0/124] Data 1.122 (1.122) Elapsed 0m 1s (remain 2m 32s) Loss: 0.3727(0.3727) \n",
      "EVAL: [100/124] Data 0.000 (0.027) Elapsed 0m 13s (remain 0m 3s) Loss: 0.2698(0.4047) \n",
      "EVAL: [123/124] Data 0.000 (0.024) Elapsed 0m 16s (remain 0m 0s) Loss: 0.7324(0.4056) \n",
      "weight = 1 evaluation score = 0.8433234095573425\n",
      "weight = 2 evaluation score = 0.795989453792572\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - avg_train_loss: 0.4899  time: 163s\n",
      "Epoch 0 - avg_val_loss: 0.4056 - avg_val_bce: 0.4067 - avg_val_comp_metric : 0.8588 - w_avg_val_comp_metric : 0.9306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7419198439274307 0.844329339235604 0.9665810492185584 0.490820657295534\n",
      "w1 = 1 w2 = 1 0.7609127224192818\n",
      "0.9413512739865532 0.9728052561585461 1.032609104900716 0.631371999823924\n",
      "w1 = 2 w2 = 4 0.8945344087174347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 1 *****\n",
      "schwarmup_last_epoch:1, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:0, scheduler_lr:4.000000000000001e-06\n",
      "optimizer_lr:4.000000000000001e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/371] Data 2.947 (2.947) Elapsed 0m 3s (remain 20m 18s) Loss: 0.3397(0.3397) Grad: 0.0000  LR: 0.0000400  \n",
      "tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [1][100/371] Data 0.000 (0.058) Elapsed 0m 39s (remain 1m 45s) Loss: 0.2763(0.4119) Grad: 0.0000  LR: 0.0000400  \n",
      "Epoch: [1][200/371] Data 0.000 (0.029) Elapsed 1m 12s (remain 1m 1s) Loss: 0.3476(0.4145) Grad: 0.0000  LR: 0.0000400  \n",
      "Epoch: [1][300/371] Data 0.000 (0.021) Elapsed 1m 45s (remain 0m 24s) Loss: 0.4329(0.4118) Grad: 0.0000  LR: 0.0000400  \n",
      "Epoch: [1][370/371] Data 0.000 (0.021) Elapsed 2m 9s (remain 0m 0s) Loss: 0.3571(0.4106) Grad: 0.0000  LR: 0.0000400  \n",
      "EVAL: [0/124] Data 1.225 (1.225) Elapsed 0m 1s (remain 2m 43s) Loss: 0.3453(0.3453) \n",
      "EVAL: [100/124] Data 0.000 (0.077) Elapsed 0m 18s (remain 0m 4s) Loss: 0.2832(0.3646) \n",
      "EVAL: [123/124] Data 0.000 (0.072) Elapsed 0m 21s (remain 0m 0s) Loss: 0.6138(0.3649) \n",
      "weight = 1 evaluation score = 0.7798622846603394\n",
      "weight = 2 evaluation score = 0.7063568830490112\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4106  time: 153s\n",
      "Epoch 1 - avg_val_loss: 0.3649 - avg_val_bce: 0.3519 - avg_val_comp_metric : 0.7835 - w_avg_val_comp_metric : 0.8019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6291199201516546 0.803136475912091 0.9072375737186068 0.42135652332701184\n",
      "w1 = 1 w2 = 1 0.690212623277341\n",
      "0.6922226124258302 0.8186479348525237 0.8870460743163279 0.47005739209367464\n",
      "w1 = 2 w2 = 4 0.7169935034220891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 2 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:0, scheduler_lr:4.000000000000001e-06\n",
      "optimizer_lr:4.000000000000001e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/371] Data 1.723 (1.723) Elapsed 0m 2s (remain 12m 41s) Loss: 0.6146(0.6146) Grad: 0.0000  LR: 0.0000400  \n",
      "tensor(0.6146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [2][100/371] Data 0.000 (0.025) Elapsed 0m 35s (remain 1m 35s) Loss: 0.4120(0.3882) Grad: 0.0000  LR: 0.0000400  \n",
      "Epoch: [2][200/371] Data 0.000 (0.013) Elapsed 1m 8s (remain 0m 58s) Loss: 0.3874(0.3996) Grad: 0.0000  LR: 0.0000400  \n",
      "Epoch: [2][300/371] Data 0.000 (0.009) Elapsed 1m 41s (remain 0m 23s) Loss: 0.4375(0.3955) Grad: 0.0000  LR: 0.0000400  \n",
      "Epoch: [2][370/371] Data 0.000 (0.007) Elapsed 2m 4s (remain 0m 0s) Loss: 1.1872(0.3890) Grad: 0.0000  LR: 0.0000400  \n",
      "EVAL: [0/124] Data 0.892 (0.892) Elapsed 0m 0s (remain 2m 2s) Loss: 0.4542(0.4542) \n",
      "EVAL: [100/124] Data 0.000 (0.013) Elapsed 0m 11s (remain 0m 2s) Loss: 0.2122(0.3578) \n",
      "EVAL: [123/124] Data 0.000 (0.011) Elapsed 0m 14s (remain 0m 0s) Loss: 0.6240(0.3570) \n",
      "weight = 1 evaluation score = 0.7925848960876465\n",
      "weight = 2 evaluation score = 0.6606663465499878\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.3890  time: 140s\n",
      "Epoch 2 - avg_val_loss: 0.3570 - avg_val_bce: 0.3195 - avg_val_comp_metric : 0.7381 - w_avg_val_comp_metric : 0.7092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.574548209540958 0.781706180024465 0.9208682263617168 0.3793652181175898\n",
      "w1 = 1 w2 = 1 0.6641219585111824\n",
      "0.5593427754576205 0.7335978266724797 0.8203052224634687 0.34317889490306225\n",
      "w1 = 2 w2 = 4 0.6141061798741578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 3 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:1, scheduler_lr:3.992812989642341e-05\n",
      "optimizer_lr:3.992812989642341e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/371] Data 2.208 (2.208) Elapsed 0m 2s (remain 15m 39s) Loss: 0.2098(0.2098) Grad: 0.0000  LR: 0.0000399  \n",
      "tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [3][100/371] Data 0.000 (0.026) Elapsed 0m 35s (remain 1m 36s) Loss: 0.3000(0.3749) Grad: 0.0000  LR: 0.0000399  \n",
      "Epoch: [3][200/371] Data 0.000 (0.013) Elapsed 1m 8s (remain 0m 58s) Loss: 0.4479(0.3818) Grad: 0.0000  LR: 0.0000399  \n",
      "Epoch: [3][300/371] Data 0.000 (0.009) Elapsed 1m 41s (remain 0m 23s) Loss: 0.1976(0.3803) Grad: 0.0000  LR: 0.0000399  \n",
      "Epoch: [3][370/371] Data 0.000 (0.007) Elapsed 2m 4s (remain 0m 0s) Loss: 0.2417(0.3790) Grad: 0.0000  LR: 0.0000399  \n",
      "EVAL: [0/124] Data 1.252 (1.252) Elapsed 0m 1s (remain 2m 47s) Loss: 0.3527(0.3527) \n",
      "EVAL: [100/124] Data 0.000 (0.027) Elapsed 0m 13s (remain 0m 3s) Loss: 0.2142(0.3320) \n",
      "EVAL: [123/124] Data 0.000 (0.022) Elapsed 0m 15s (remain 0m 0s) Loss: 0.5607(0.3309) \n",
      "weight = 1 evaluation score = 0.6532269716262817\n",
      "weight = 2 evaluation score = 0.5965549945831299\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.3790  time: 141s\n",
      "Epoch 3 - avg_val_loss: 0.3309 - avg_val_bce: 0.3204 - avg_val_comp_metric : 0.6835 - w_avg_val_comp_metric : 0.7002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5232840493932013 0.731886144536415 0.8149411062710912 0.3146891214030798\n",
      "w1 = 1 w2 = 1 0.5962001054009469\n",
      "0.5627235420429982 0.7467980966202015 0.8025739479529698 0.36403066373127707\n",
      "w1 = 2 w2 = 4 0.6190315625868617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 4 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:2, scheduler_lr:3.971303741143679e-05\n",
      "optimizer_lr:3.971303741143679e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/371] Data 2.366 (2.366) Elapsed 0m 2s (remain 16m 38s) Loss: 0.3830(0.3830) Grad: 0.0000  LR: 0.0000397  \n",
      "tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [4][100/371] Data 0.403 (0.037) Elapsed 0m 37s (remain 1m 38s) Loss: 0.3673(0.3603) Grad: 0.0000  LR: 0.0000397  \n",
      "Epoch: [4][200/371] Data 0.000 (0.019) Elapsed 1m 9s (remain 0m 59s) Loss: 0.3788(0.3735) Grad: 0.0000  LR: 0.0000397  \n",
      "Epoch: [4][300/371] Data 0.000 (0.013) Elapsed 1m 42s (remain 0m 23s) Loss: 0.4839(0.3794) Grad: 0.0000  LR: 0.0000397  \n",
      "Epoch: [4][370/371] Data 0.000 (0.010) Elapsed 2m 5s (remain 0m 0s) Loss: 0.0640(0.3739) Grad: 0.0000  LR: 0.0000397  \n",
      "EVAL: [0/124] Data 1.231 (1.231) Elapsed 0m 1s (remain 2m 44s) Loss: 0.4184(0.4184) \n",
      "EVAL: [100/124] Data 0.000 (0.017) Elapsed 0m 12s (remain 0m 2s) Loss: 0.1691(0.3702) \n",
      "EVAL: [123/124] Data 0.000 (0.014) Elapsed 0m 14s (remain 0m 0s) Loss: 0.7510(0.3726) \n",
      "weight = 1 evaluation score = 0.8110330104827881\n",
      "weight = 2 evaluation score = 0.6556797027587891\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.3739  time: 141s\n",
      "Epoch 4 - avg_val_loss: 0.3726 - avg_val_bce: 0.3122 - avg_val_comp_metric : 0.7292 - w_avg_val_comp_metric : 0.6746\n",
      "***** Epoch 5 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:3, scheduler_lr:3.935627229132331e-05\n",
      "optimizer_lr:3.935627229132331e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.588497845975669 0.8282757858311082 0.9399402745721676 0.35893896704343736\n",
      "w1 = 1 w2 = 1 0.6789132183555956\n",
      "0.5125645302195473 0.7216581092665411 0.7948323837758897 0.33371511809617477\n",
      "w1 = 2 w2 = 4 0.5906925353395382\n",
      "Epoch: [5][0/371] Data 2.083 (2.083) Elapsed 0m 2s (remain 14m 54s) Loss: 0.3826(0.3826) Grad: 0.0000  LR: 0.0000394  \n",
      "tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [5][100/371] Data 0.000 (0.028) Elapsed 0m 36s (remain 1m 36s) Loss: 0.3838(0.3647) Grad: 0.0000  LR: 0.0000394  \n",
      "Epoch: [5][200/371] Data 0.000 (0.014) Elapsed 1m 8s (remain 0m 58s) Loss: 0.3223(0.3670) Grad: 0.0000  LR: 0.0000394  \n",
      "Epoch: [5][300/371] Data 0.000 (0.010) Elapsed 1m 41s (remain 0m 23s) Loss: 0.4357(0.3734) Grad: 0.0000  LR: 0.0000394  \n",
      "Epoch: [5][370/371] Data 0.000 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.1530(0.3709) Grad: 0.0000  LR: 0.0000394  \n",
      "EVAL: [0/124] Data 1.508 (1.508) Elapsed 0m 1s (remain 3m 18s) Loss: 0.3108(0.3108) \n",
      "EVAL: [100/124] Data 0.000 (0.055) Elapsed 0m 16s (remain 0m 3s) Loss: 0.2371(0.3299) \n",
      "EVAL: [123/124] Data 0.000 (0.060) Elapsed 0m 20s (remain 0m 0s) Loss: 0.5599(0.3295) \n",
      "weight = 1 evaluation score = 0.6468418836593628\n",
      "weight = 2 evaluation score = 0.604402482509613\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.3709  time: 146s\n",
      "Epoch 5 - avg_val_loss: 0.3295 - avg_val_bce: 0.3287 - avg_val_comp_metric : 0.6891 - w_avg_val_comp_metric : 0.7129\n",
      "***** Epoch 6 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:4, scheduler_lr:3.886040503694863e-05\n",
      "optimizer_lr:3.886040503694863e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5257845532326325 0.7393807701807827 0.8023380651988927 0.31510656620782723\n",
      "w1 = 1 w2 = 1 0.5956524887050338\n",
      "0.5762823550182056 0.7644696688543574 0.8213662650465948 0.35679152471692205\n",
      "w1 = 2 w2 = 4 0.62972745340902\n",
      "Epoch: [6][0/371] Data 1.759 (1.759) Elapsed 0m 2s (remain 12m 55s) Loss: 0.3744(0.3744) Grad: 0.0000  LR: 0.0000389  \n",
      "tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [6][100/371] Data 0.000 (0.020) Elapsed 0m 35s (remain 1m 34s) Loss: 0.3577(0.3760) Grad: 0.0000  LR: 0.0000389  \n",
      "Epoch: [6][200/371] Data 0.000 (0.010) Elapsed 1m 8s (remain 0m 57s) Loss: 0.2002(0.3737) Grad: 0.0000  LR: 0.0000389  \n",
      "Epoch: [6][300/371] Data 0.000 (0.007) Elapsed 1m 41s (remain 0m 23s) Loss: 0.3942(0.3644) Grad: 0.0000  LR: 0.0000389  \n",
      "Epoch: [6][370/371] Data 0.000 (0.006) Elapsed 2m 4s (remain 0m 0s) Loss: 0.1779(0.3616) Grad: 0.0000  LR: 0.0000389  \n",
      "EVAL: [0/124] Data 0.877 (0.877) Elapsed 0m 0s (remain 2m 0s) Loss: 0.3298(0.3298) \n",
      "EVAL: [100/124] Data 0.000 (0.012) Elapsed 0m 11s (remain 0m 2s) Loss: 0.2513(0.3187) \n",
      "EVAL: [123/124] Data 0.000 (0.010) Elapsed 0m 14s (remain 0m 0s) Loss: 0.5635(0.3187) \n",
      "weight = 1 evaluation score = 0.5807062387466431\n",
      "weight = 2 evaluation score = 0.5498682856559753\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.3616  time: 139s\n",
      "Epoch 6 - avg_val_loss: 0.3187 - avg_val_bce: 0.3120 - avg_val_comp_metric : 0.6326 - w_avg_val_comp_metric : 0.6642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4575715703538093 0.7164079644640079 0.7829124485367001 0.25572843629187864\n",
      "w1 = 1 w2 = 1 0.553155104911599\n",
      "0.5196367430637133 0.7567231656672391 0.7701882043916575 0.32923187352667926\n",
      "w1 = 2 w2 = 4 0.5939449966623223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 7 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:5, scheduler_lr:3.8229008383243314e-05\n",
      "optimizer_lr:3.8229008383243314e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][0/371] Data 1.876 (1.876) Elapsed 0m 2s (remain 13m 36s) Loss: 0.5772(0.5772) Grad: 0.0000  LR: 0.0000382  \n",
      "tensor(0.5772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [7][100/371] Data 0.000 (0.035) Elapsed 0m 36s (remain 1m 38s) Loss: 0.2686(0.3655) Grad: 0.0000  LR: 0.0000382  \n",
      "Epoch: [7][200/371] Data 0.000 (0.018) Elapsed 1m 9s (remain 0m 58s) Loss: 0.4867(0.3621) Grad: 0.0000  LR: 0.0000382  \n",
      "Epoch: [7][300/371] Data 0.000 (0.012) Elapsed 1m 42s (remain 0m 23s) Loss: 0.3827(0.3629) Grad: 0.0000  LR: 0.0000382  \n",
      "Epoch: [7][370/371] Data 0.000 (0.010) Elapsed 2m 5s (remain 0m 0s) Loss: 0.7311(0.3589) Grad: 0.0000  LR: 0.0000382  \n",
      "EVAL: [0/124] Data 1.219 (1.219) Elapsed 0m 1s (remain 2m 42s) Loss: 0.3375(0.3375) \n",
      "EVAL: [100/124] Data 0.000 (0.033) Elapsed 0m 13s (remain 0m 3s) Loss: 0.2225(0.3122) \n",
      "EVAL: [123/124] Data 0.000 (0.033) Elapsed 0m 16s (remain 0m 0s) Loss: 0.5456(0.3126) \n",
      "weight = 1 evaluation score = 0.5883018970489502\n",
      "weight = 2 evaluation score = 0.5394165515899658\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.3589  time: 143s\n",
      "Epoch 7 - avg_val_loss: 0.3126 - avg_val_bce: 0.3004 - avg_val_comp_metric : 0.6267 - w_avg_val_comp_metric : 0.6445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4546708077363768 0.719868699173662 0.7631989532907599 0.25986737802045634\n",
      "w1 = 1 w2 = 1 0.5494014595553138\n",
      "0.5007205938967226 0.7011659238495568 0.7503790893559256 0.32840748940299386\n",
      "w1 = 2 w2 = 4 0.5701682741262998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 8 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:6, scheduler_lr:3.746663155756571e-05\n",
      "optimizer_lr:3.746663155756571e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][0/371] Data 2.333 (2.333) Elapsed 0m 2s (remain 16m 25s) Loss: 0.2220(0.2220) Grad: 0.0000  LR: 0.0000375  \n",
      "tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [8][100/371] Data 0.000 (0.026) Elapsed 0m 35s (remain 1m 35s) Loss: 0.1933(0.3640) Grad: 0.0000  LR: 0.0000375  \n",
      "Epoch: [8][200/371] Data 0.000 (0.015) Elapsed 1m 9s (remain 0m 58s) Loss: 0.2768(0.3481) Grad: 0.0000  LR: 0.0000375  \n",
      "Epoch: [8][300/371] Data 0.000 (0.010) Elapsed 1m 41s (remain 0m 23s) Loss: 0.4499(0.3501) Grad: 0.0000  LR: 0.0000375  \n",
      "Epoch: [8][370/371] Data 0.000 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.3230(0.3559) Grad: 0.0000  LR: 0.0000375  \n",
      "EVAL: [0/124] Data 0.929 (0.929) Elapsed 0m 1s (remain 2m 7s) Loss: 0.2748(0.2748) \n",
      "EVAL: [100/124] Data 0.000 (0.055) Elapsed 0m 16s (remain 0m 3s) Loss: 0.2247(0.3151) \n",
      "EVAL: [123/124] Data 0.000 (0.045) Elapsed 0m 18s (remain 0m 0s) Loss: 0.5519(0.3158) \n",
      "weight = 1 evaluation score = 0.6143432259559631\n",
      "weight = 2 evaluation score = 0.5647534728050232\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.3559  time: 144s\n",
      "Epoch 8 - avg_val_loss: 0.3158 - avg_val_bce: 0.3109 - avg_val_comp_metric : 0.6571 - w_avg_val_comp_metric : 0.6731\n",
      "***** Epoch 9 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:7, scheduler_lr:3.657876750241466e-05\n",
      "optimizer_lr:3.657876750241466e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.486366443707522 0.7248331422497347 0.7882382540027053 0.2833273089366249\n",
      "w1 = 1 w2 = 1 0.5706912872241467\n",
      "0.5444867835738466 0.7111917711197665 0.7736094558341932 0.3212174751592679\n",
      "w1 = 2 w2 = 4 0.5876263714217685\n",
      "Epoch: [9][0/371] Data 1.618 (1.618) Elapsed 0m 1s (remain 12m 2s) Loss: 0.3198(0.3198) Grad: 0.0000  LR: 0.0000366  \n",
      "tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [9][100/371] Data 0.000 (0.033) Elapsed 0m 36s (remain 1m 37s) Loss: 0.1124(0.3452) Grad: 0.0000  LR: 0.0000366  \n",
      "Epoch: [9][200/371] Data 0.000 (0.019) Elapsed 1m 9s (remain 0m 59s) Loss: 0.3433(0.3520) Grad: 0.0000  LR: 0.0000366  \n",
      "Epoch: [9][300/371] Data 0.000 (0.013) Elapsed 1m 42s (remain 0m 23s) Loss: 0.1597(0.3501) Grad: 0.0000  LR: 0.0000366  \n",
      "Epoch: [9][370/371] Data 0.000 (0.011) Elapsed 2m 6s (remain 0m 0s) Loss: 0.2452(0.3500) Grad: 0.0000  LR: 0.0000366  \n",
      "EVAL: [0/124] Data 1.349 (1.349) Elapsed 0m 1s (remain 2m 59s) Loss: 0.3282(0.3282) \n",
      "EVAL: [100/124] Data 0.000 (0.052) Elapsed 0m 15s (remain 0m 3s) Loss: 0.2217(0.3072) \n",
      "EVAL: [123/124] Data 0.000 (0.054) Elapsed 0m 19s (remain 0m 0s) Loss: 0.6183(0.3083) \n",
      "weight = 1 evaluation score = 0.5972748398780823\n",
      "weight = 2 evaluation score = 0.5348361730575562\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.3500  time: 146s\n",
      "Epoch 9 - avg_val_loss: 0.3083 - avg_val_bce: 0.2930 - avg_val_comp_metric : 0.6230 - w_avg_val_comp_metric : 0.6251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4758730510702443 0.6906866767656276 0.7714362500440402 0.2571118636744634\n",
      "w1 = 1 w2 = 1 0.5487769603885939\n",
      "0.48977459501451126 0.6838273544807226 0.7281667345475067 0.27620842696873577\n",
      "w1 = 2 w2 = 4 0.5444942777528691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 10 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:8, scheduler_lr:3.557181329865287e-05\n",
      "optimizer_lr:3.557181329865287e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][0/371] Data 2.162 (2.162) Elapsed 0m 2s (remain 15m 22s) Loss: 0.3140(0.3140) Grad: 0.0000  LR: 0.0000356  \n",
      "tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [10][100/371] Data 0.000 (0.046) Elapsed 0m 37s (remain 1m 41s) Loss: 0.3556(0.3415) Grad: 0.0000  LR: 0.0000356  \n",
      "Epoch: [10][200/371] Data 0.000 (0.023) Elapsed 1m 10s (remain 1m 0s) Loss: 0.3633(0.3442) Grad: 0.0000  LR: 0.0000356  \n",
      "Epoch: [10][300/371] Data 0.000 (0.016) Elapsed 1m 43s (remain 0m 24s) Loss: 0.2755(0.3438) Grad: 0.0000  LR: 0.0000356  \n",
      "Epoch: [10][370/371] Data 0.000 (0.013) Elapsed 2m 6s (remain 0m 0s) Loss: 0.1047(0.3468) Grad: 0.0000  LR: 0.0000356  \n",
      "EVAL: [0/124] Data 0.980 (0.980) Elapsed 0m 1s (remain 2m 13s) Loss: 0.3630(0.3630) \n",
      "EVAL: [100/124] Data 0.000 (0.045) Elapsed 0m 15s (remain 0m 3s) Loss: 0.1686(0.3120) \n",
      "EVAL: [123/124] Data 0.000 (0.037) Elapsed 0m 17s (remain 0m 0s) Loss: 0.5477(0.3146) \n",
      "weight = 1 evaluation score = 0.6516157388687134\n",
      "weight = 2 evaluation score = 0.5585022568702698\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.3468  time: 145s\n",
      "Epoch 10 - avg_val_loss: 0.3146 - avg_val_bce: 0.2922 - avg_val_comp_metric : 0.6509 - w_avg_val_comp_metric : 0.6392\n",
      "***** Epoch 11 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:9, scheduler_lr:3.445302407439277e-05\n",
      "optimizer_lr:3.445302407439277e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4880394485056038 0.720777680696926 0.7978739811584754 0.29071456888345887\n",
      "w1 = 1 w2 = 1 0.574351419811116\n",
      "0.48492349382563565 0.6725962614939152 0.7297730834353466 0.2895126351975475\n",
      "w1 = 2 w2 = 4 0.5442013684881113\n",
      "Epoch: [11][0/371] Data 2.299 (2.299) Elapsed 0m 2s (remain 16m 14s) Loss: 0.2549(0.2549) Grad: 0.0000  LR: 0.0000345  \n",
      "tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [11][100/371] Data 0.000 (0.029) Elapsed 0m 36s (remain 1m 36s) Loss: 0.3225(0.3479) Grad: 0.0000  LR: 0.0000345  \n",
      "Epoch: [11][200/371] Data 0.000 (0.016) Elapsed 1m 9s (remain 0m 58s) Loss: 0.4182(0.3439) Grad: 0.0000  LR: 0.0000345  \n",
      "Epoch: [11][300/371] Data 0.000 (0.013) Elapsed 1m 42s (remain 0m 23s) Loss: 0.4705(0.3460) Grad: 0.0000  LR: 0.0000345  \n",
      "Epoch: [11][370/371] Data 0.000 (0.013) Elapsed 2m 6s (remain 0m 0s) Loss: 0.0587(0.3466) Grad: 0.0000  LR: 0.0000345  \n",
      "EVAL: [0/124] Data 0.826 (0.826) Elapsed 0m 0s (remain 1m 54s) Loss: 0.2820(0.2820) \n",
      "EVAL: [100/124] Data 0.211 (0.053) Elapsed 0m 15s (remain 0m 3s) Loss: 0.2695(0.3097) \n",
      "EVAL: [123/124] Data 0.000 (0.052) Elapsed 0m 19s (remain 0m 0s) Loss: 0.5067(0.3097) \n",
      "weight = 1 evaluation score = 0.5558682680130005\n",
      "weight = 2 evaluation score = 0.5407779216766357\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - avg_train_loss: 0.3466  time: 146s\n",
      "Epoch 11 - avg_val_loss: 0.3097 - avg_val_bce: 0.3116 - avg_val_comp_metric : 0.6200 - w_avg_val_comp_metric : 0.6605\n",
      "***** Epoch 12 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:10, scheduler_lr:3.3230460731632125e-05\n",
      "optimizer_lr:3.3230460731632125e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44991999480669626 0.6805130239698972 0.7357822004079313 0.2563683484371655\n",
      "w1 = 1 w2 = 1 0.5306458919054226\n",
      "0.5325241439809516 0.7185013174543983 0.7750842015529342 0.3053140335327898\n",
      "w1 = 2 w2 = 4 0.5828559241302684\n",
      "Epoch: [12][0/371] Data 1.296 (1.296) Elapsed 0m 1s (remain 10m 2s) Loss: 0.2801(0.2801) Grad: 0.0000  LR: 0.0000332  \n",
      "tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [12][100/371] Data 0.000 (0.041) Elapsed 0m 37s (remain 1m 39s) Loss: 0.3688(0.3493) Grad: 0.0000  LR: 0.0000332  \n",
      "Epoch: [12][200/371] Data 0.000 (0.032) Elapsed 1m 12s (remain 1m 1s) Loss: 0.4242(0.3453) Grad: 0.0000  LR: 0.0000332  \n",
      "Epoch: [12][300/371] Data 0.000 (0.022) Elapsed 1m 45s (remain 0m 24s) Loss: 0.4769(0.3455) Grad: 0.0000  LR: 0.0000332  \n",
      "Epoch: [12][370/371] Data 0.000 (0.018) Elapsed 2m 8s (remain 0m 0s) Loss: 0.9055(0.3442) Grad: 0.0000  LR: 0.0000332  \n",
      "EVAL: [0/124] Data 1.577 (1.577) Elapsed 0m 1s (remain 3m 27s) Loss: 0.3202(0.3202) \n",
      "EVAL: [100/124] Data 0.438 (0.088) Elapsed 0m 19s (remain 0m 4s) Loss: 0.2203(0.2968) \n",
      "EVAL: [123/124] Data 0.000 (0.076) Elapsed 0m 22s (remain 0m 0s) Loss: 0.5652(0.2977) \n",
      "weight = 1 evaluation score = 0.5686427354812622\n",
      "weight = 2 evaluation score = 0.517372190952301\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - avg_train_loss: 0.3442  time: 152s\n",
      "Epoch 12 - avg_val_loss: 0.2977 - avg_val_bce: 0.2906 - avg_val_comp_metric : 0.6097 - w_avg_val_comp_metric : 0.6245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44147237120780786 0.6664600855592127 0.7422050880067745 0.2538106886890563\n",
      "w1 = 1 w2 = 1 0.5259870583657129\n",
      "0.4588434347830548 0.6813056356847625 0.726552739872618 0.28772742023283726\n",
      "w1 = 2 w2 = 4 0.5386073076433182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 13 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:11, scheduler_lr:3.1912931867270525e-05\n",
      "optimizer_lr:3.1912931867270525e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13][0/371] Data 1.605 (1.605) Elapsed 0m 1s (remain 11m 56s) Loss: 0.6996(0.6996) Grad: 0.0000  LR: 0.0000319  \n",
      "tensor(0.6996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [13][100/371] Data 0.000 (0.022) Elapsed 0m 35s (remain 1m 34s) Loss: 0.2937(0.3511) Grad: 0.0000  LR: 0.0000319  \n",
      "Epoch: [13][200/371] Data 0.000 (0.011) Elapsed 1m 8s (remain 0m 57s) Loss: 0.2594(0.3459) Grad: 0.0000  LR: 0.0000319  \n",
      "Epoch: [13][300/371] Data 0.000 (0.007) Elapsed 1m 41s (remain 0m 23s) Loss: 0.4481(0.3449) Grad: 0.0000  LR: 0.0000319  \n",
      "Epoch: [13][370/371] Data 0.000 (0.006) Elapsed 2m 3s (remain 0m 0s) Loss: 0.2752(0.3394) Grad: 0.0000  LR: 0.0000319  \n",
      "EVAL: [0/124] Data 0.974 (0.974) Elapsed 0m 1s (remain 2m 13s) Loss: 0.2963(0.2963) \n",
      "EVAL: [100/124] Data 0.000 (0.052) Elapsed 0m 15s (remain 0m 3s) Loss: 0.2450(0.3029) \n",
      "EVAL: [123/124] Data 0.000 (0.055) Elapsed 0m 19s (remain 0m 0s) Loss: 0.5268(0.3040) \n",
      "weight = 1 evaluation score = 0.5487306118011475\n",
      "weight = 2 evaluation score = 0.5275546312332153\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - avg_train_loss: 0.3394  time: 144s\n",
      "Epoch 13 - avg_val_loss: 0.3040 - avg_val_bce: 0.3021 - avg_val_comp_metric : 0.6081 - w_avg_val_comp_metric : 0.6418\n",
      "***** Epoch 14 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:12, scheduler_lr:3.0509930306966776e-05\n",
      "optimizer_lr:3.0509930306966776e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44303117913179985 0.6664994870027248 0.7225995568716662 0.2446269714742354\n",
      "w1 = 1 w2 = 1 0.5191892986201065\n",
      "0.5104887553474988 0.7081598148189997 0.7554716126414138 0.28083960666922814\n",
      "w1 = 2 w2 = 4 0.5637399473692851\n",
      "Epoch: [14][0/371] Data 1.936 (1.936) Elapsed 0m 2s (remain 13m 59s) Loss: 0.2211(0.2211) Grad: 0.0000  LR: 0.0000305  \n",
      "tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [14][100/371] Data 0.000 (0.019) Elapsed 0m 35s (remain 1m 34s) Loss: 0.3182(0.3532) Grad: 0.0000  LR: 0.0000305  \n",
      "Epoch: [14][200/371] Data 0.000 (0.010) Elapsed 1m 8s (remain 0m 57s) Loss: 0.2724(0.3441) Grad: 0.0000  LR: 0.0000305  \n",
      "Epoch: [14][300/371] Data 0.000 (0.007) Elapsed 1m 40s (remain 0m 23s) Loss: 0.4179(0.3377) Grad: 0.0000  LR: 0.0000305  \n",
      "Epoch: [14][370/371] Data 0.000 (0.005) Elapsed 2m 3s (remain 0m 0s) Loss: 0.4711(0.3355) Grad: 0.0000  LR: 0.0000305  \n",
      "EVAL: [0/124] Data 0.859 (0.859) Elapsed 0m 0s (remain 1m 58s) Loss: 0.2847(0.2847) \n",
      "EVAL: [100/124] Data 0.000 (0.096) Elapsed 0m 20s (remain 0m 4s) Loss: 0.2362(0.2973) \n",
      "EVAL: [123/124] Data 0.000 (0.082) Elapsed 0m 22s (remain 0m 0s) Loss: 0.4874(0.2989) \n",
      "weight = 1 evaluation score = 0.5610416531562805\n",
      "weight = 2 evaluation score = 0.5272297263145447\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - avg_train_loss: 0.3355  time: 147s\n",
      "Epoch 14 - avg_val_loss: 0.2989 - avg_val_bce: 0.2969 - avg_val_comp_metric : 0.6162 - w_avg_val_comp_metric : 0.6417\n",
      "***** Epoch 15 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:13, scheduler_lr:2.9031564709112585e-05\n",
      "optimizer_lr:2.9031564709112585e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4485568599490395 0.6905235789650456 0.7331581652298359 0.2576312232582993\n",
      "w1 = 1 w2 = 1 0.5324674568505551\n",
      "0.5218942405394282 0.6781528334848552 0.7362854417904885 0.31838022566597934\n",
      "w1 = 2 w2 = 4 0.5636781853701878\n",
      "Epoch: [15][0/371] Data 2.313 (2.313) Elapsed 0m 2s (remain 16m 20s) Loss: 0.2398(0.2398) Grad: 0.0000  LR: 0.0000290  \n",
      "tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [15][100/371] Data 0.000 (0.033) Elapsed 0m 36s (remain 1m 37s) Loss: 0.2442(0.3257) Grad: 0.0000  LR: 0.0000290  \n",
      "Epoch: [15][200/371] Data 0.000 (0.021) Elapsed 1m 10s (remain 0m 59s) Loss: 0.4278(0.3373) Grad: 0.0000  LR: 0.0000290  \n",
      "Epoch: [15][300/371] Data 0.000 (0.014) Elapsed 1m 43s (remain 0m 23s) Loss: 0.2687(0.3418) Grad: 0.0000  LR: 0.0000290  \n",
      "Epoch: [15][370/371] Data 0.000 (0.015) Elapsed 2m 7s (remain 0m 0s) Loss: 0.0668(0.3408) Grad: 0.0000  LR: 0.0000290  \n",
      "EVAL: [0/124] Data 0.971 (0.971) Elapsed 0m 1s (remain 2m 12s) Loss: 0.3100(0.3100) \n",
      "EVAL: [100/124] Data 0.000 (0.030) Elapsed 0m 13s (remain 0m 3s) Loss: 0.1910(0.2974) \n",
      "EVAL: [123/124] Data 0.000 (0.024) Elapsed 0m 15s (remain 0m 0s) Loss: 0.5278(0.2988) \n",
      "weight = 1 evaluation score = 0.6310693025588989\n",
      "weight = 2 evaluation score = 0.5502581596374512\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - avg_train_loss: 0.3408  time: 144s\n",
      "Epoch 15 - avg_val_loss: 0.2988 - avg_val_bce: 0.2894 - avg_val_comp_metric : 0.6426 - w_avg_val_comp_metric : 0.6312\n",
      "***** Epoch 16 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:14, scheduler_lr:2.7488486731717165e-05\n",
      "optimizer_lr:2.7488486731717165e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.477127341279303 0.6886673833008714 0.7694034388889889 0.29142271585760093\n",
      "w1 = 1 w2 = 1 0.5566552198316911\n",
      "0.47346976208850367 0.670187358809683 0.727843531528016 0.2590454422902915\n",
      "w1 = 2 w2 = 4 0.5326365236791235\n",
      "Epoch: [16][0/371] Data 1.610 (1.610) Elapsed 0m 1s (remain 11m 59s) Loss: 0.3067(0.3067) Grad: 0.0000  LR: 0.0000275  \n",
      "tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [16][100/371] Data 0.000 (0.025) Elapsed 0m 35s (remain 1m 35s) Loss: 0.3555(0.3431) Grad: 0.0000  LR: 0.0000275  \n",
      "Epoch: [16][200/371] Data 0.052 (0.017) Elapsed 1m 9s (remain 0m 58s) Loss: 0.3650(0.3409) Grad: 0.0000  LR: 0.0000275  \n",
      "Epoch: [16][300/371] Data 0.000 (0.018) Elapsed 1m 44s (remain 0m 24s) Loss: 0.2760(0.3379) Grad: 0.0000  LR: 0.0000275  \n",
      "Epoch: [16][370/371] Data 0.000 (0.015) Elapsed 2m 7s (remain 0m 0s) Loss: 0.4350(0.3363) Grad: 0.0000  LR: 0.0000275  \n",
      "EVAL: [0/124] Data 1.191 (1.191) Elapsed 0m 1s (remain 2m 39s) Loss: 0.2726(0.2726) \n",
      "EVAL: [100/124] Data 0.000 (0.031) Elapsed 0m 13s (remain 0m 3s) Loss: 0.2355(0.2941) \n",
      "EVAL: [123/124] Data 0.000 (0.031) Elapsed 0m 16s (remain 0m 0s) Loss: 0.5254(0.2952) \n",
      "weight = 1 evaluation score = 0.5332831740379333\n",
      "weight = 2 evaluation score = 0.5102960467338562\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - avg_train_loss: 0.3363  time: 145s\n",
      "Epoch 16 - avg_val_loss: 0.2952 - avg_val_bce: 0.2850 - avg_val_comp_metric : 0.5850 - w_avg_val_comp_metric : 0.6168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4311995713043213 0.6646934106848551 0.7029762874159668 0.2579591163515421\n",
      "w1 = 1 w2 = 1 0.5142070964391713\n",
      "0.49765834331346565 0.6563620966722784 0.703217252263803 0.34963551437779955\n",
      "w1 = 2 w2 = 4 0.5517183016568367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 17 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:15, scheduler_lr:2.5891814286967183e-05\n",
      "optimizer_lr:2.5891814286967183e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17][0/371] Data 1.897 (1.897) Elapsed 0m 2s (remain 13m 44s) Loss: 0.5513(0.5513) Grad: 0.0000  LR: 0.0000259  \n",
      "tensor(0.5513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [17][100/371] Data 0.000 (0.027) Elapsed 0m 36s (remain 1m 36s) Loss: 0.1242(0.3276) Grad: 0.0000  LR: 0.0000259  \n",
      "Epoch: [17][200/371] Data 0.000 (0.014) Elapsed 1m 8s (remain 0m 58s) Loss: 0.3232(0.3269) Grad: 0.0000  LR: 0.0000259  \n",
      "Epoch: [17][300/371] Data 0.000 (0.009) Elapsed 1m 41s (remain 0m 23s) Loss: 0.3435(0.3329) Grad: 0.0000  LR: 0.0000259  \n",
      "Epoch: [17][370/371] Data 0.000 (0.007) Elapsed 2m 4s (remain 0m 0s) Loss: 0.0385(0.3321) Grad: 0.0000  LR: 0.0000259  \n",
      "EVAL: [0/124] Data 0.836 (0.836) Elapsed 0m 0s (remain 1m 55s) Loss: 0.2583(0.2583) \n",
      "EVAL: [100/124] Data 0.000 (0.064) Elapsed 0m 16s (remain 0m 3s) Loss: 0.2563(0.2938) \n",
      "EVAL: [123/124] Data 0.000 (0.067) Elapsed 0m 21s (remain 0m 0s) Loss: 0.4966(0.2943) \n",
      "weight = 1 evaluation score = 0.5419021844863892\n",
      "weight = 2 evaluation score = 0.5207644104957581\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - avg_train_loss: 0.3321  time: 146s\n",
      "Epoch 17 - avg_val_loss: 0.2943 - avg_val_bce: 0.2983 - avg_val_comp_metric : 0.6064 - w_avg_val_comp_metric : 0.6413\n",
      "***** Epoch 18 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:16, scheduler_lr:2.425305143641475e-05\n",
      "optimizer_lr:2.425305143641475e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4327260378370324 0.6554664439108571 0.7129616206206089 0.25715410318744786\n",
      "w1 = 1 w2 = 1 0.5145770513889866\n",
      "0.49667158542134415 0.697149408347136 0.7396315157992459 0.31231094141406696\n",
      "w1 = 2 w2 = 4 0.5614408627454482\n",
      "Epoch: [18][0/371] Data 1.640 (1.640) Elapsed 0m 1s (remain 12m 9s) Loss: 0.2743(0.2743) Grad: 0.0000  LR: 0.0000243  \n",
      "tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [18][100/371] Data 0.000 (0.048) Elapsed 0m 38s (remain 1m 42s) Loss: 0.2523(0.3197) Grad: 0.0000  LR: 0.0000243  \n",
      "Epoch: [18][200/371] Data 0.181 (0.029) Elapsed 1m 12s (remain 1m 1s) Loss: 0.3564(0.3273) Grad: 0.0000  LR: 0.0000243  \n",
      "Epoch: [18][300/371] Data 0.000 (0.021) Elapsed 1m 45s (remain 0m 24s) Loss: 0.3290(0.3293) Grad: 0.0000  LR: 0.0000243  \n",
      "Epoch: [18][370/371] Data 0.000 (0.017) Elapsed 2m 8s (remain 0m 0s) Loss: 0.1995(0.3296) Grad: 0.0000  LR: 0.0000243  \n",
      "EVAL: [0/124] Data 0.929 (0.929) Elapsed 0m 1s (remain 2m 7s) Loss: 0.3010(0.3010) \n",
      "EVAL: [100/124] Data 0.000 (0.079) Elapsed 0m 18s (remain 0m 4s) Loss: 0.2173(0.2916) \n",
      "EVAL: [123/124] Data 0.000 (0.065) Elapsed 0m 20s (remain 0m 0s) Loss: 0.5521(0.2930) \n",
      "weight = 1 evaluation score = 0.5646964311599731\n",
      "weight = 2 evaluation score = 0.5143760442733765\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - avg_train_loss: 0.3296  time: 150s\n",
      "Epoch 18 - avg_val_loss: 0.2930 - avg_val_bce: 0.2871 - avg_val_comp_metric : 0.6069 - w_avg_val_comp_metric : 0.6213\n",
      "***** Epoch 19 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:17, scheduler_lr:2.2584005503950234e-05\n",
      "optimizer_lr:2.2584005503950234e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44962804235522164 0.647039780103251 0.7398806341841014 0.25482112227977877\n",
      "w1 = 1 w2 = 1 0.5228423947305882\n",
      "0.4605028955277191 0.6791896029374144 0.7180216024692523 0.29226014684450907\n",
      "w1 = 2 w2 = 4 0.5374935619447238\n",
      "Epoch: [19][0/371] Data 1.708 (1.708) Elapsed 0m 2s (remain 12m 35s) Loss: 0.2844(0.2844) Grad: 0.0000  LR: 0.0000226  \n",
      "tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [19][100/371] Data 0.000 (0.033) Elapsed 0m 36s (remain 1m 37s) Loss: 0.5861(0.3354) Grad: 0.0000  LR: 0.0000226  \n",
      "Epoch: [19][200/371] Data 0.000 (0.020) Elapsed 1m 10s (remain 0m 59s) Loss: 0.2205(0.3241) Grad: 0.0000  LR: 0.0000226  \n",
      "Epoch: [19][300/371] Data 0.000 (0.014) Elapsed 1m 43s (remain 0m 24s) Loss: 0.3309(0.3235) Grad: 0.0000  LR: 0.0000226  \n",
      "Epoch: [19][370/371] Data 0.000 (0.011) Elapsed 2m 6s (remain 0m 0s) Loss: 0.5598(0.3280) Grad: 0.0000  LR: 0.0000226  \n",
      "EVAL: [0/124] Data 1.421 (1.421) Elapsed 0m 1s (remain 3m 7s) Loss: 0.2847(0.2847) \n",
      "EVAL: [100/124] Data 0.000 (0.040) Elapsed 0m 14s (remain 0m 3s) Loss: 0.2461(0.2928) \n",
      "EVAL: [123/124] Data 0.000 (0.036) Elapsed 0m 17s (remain 0m 0s) Loss: 0.4839(0.2933) \n",
      "weight = 1 evaluation score = 0.5388726592063904\n",
      "weight = 2 evaluation score = 0.518290638923645\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - avg_train_loss: 0.3280  time: 144s\n",
      "Epoch 19 - avg_val_loss: 0.2933 - avg_val_bce: 0.2995 - avg_val_comp_metric : 0.6103 - w_avg_val_comp_metric : 0.6505\n",
      "***** Epoch 20 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:18, scheduler_lr:2.0896702003763166e-05\n",
      "optimizer_lr:2.0896702003763166e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4359242637299125 0.6657660671992655 0.7114114203636848 0.257185105162947\n",
      "w1 = 1 w2 = 1 0.5175717141139524\n",
      "0.5033150078345504 0.7009720815162065 0.7431028412134201 0.3413075329940943\n",
      "w1 = 2 w2 = 4 0.5721743658895678\n",
      "Epoch: [20][0/371] Data 2.285 (2.285) Elapsed 0m 2s (remain 16m 8s) Loss: 0.2182(0.2182) Grad: 0.0000  LR: 0.0000209  \n",
      "tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [20][100/371] Data 0.000 (0.142) Elapsed 0m 47s (remain 2m 7s) Loss: 0.6258(0.3348) Grad: 0.0000  LR: 0.0000209  \n",
      "Epoch: [20][200/371] Data 0.000 (0.124) Elapsed 1m 31s (remain 1m 17s) Loss: 0.2557(0.3297) Grad: 0.0000  LR: 0.0000209  \n",
      "Epoch: [20][300/371] Data 0.000 (0.132) Elapsed 2m 19s (remain 0m 32s) Loss: 0.1286(0.3244) Grad: 0.0000  LR: 0.0000209  \n",
      "Epoch: [20][370/371] Data 0.000 (0.119) Elapsed 2m 46s (remain 0m 0s) Loss: 0.1919(0.3244) Grad: 0.0000  LR: 0.0000209  \n",
      "EVAL: [0/124] Data 0.943 (0.943) Elapsed 0m 1s (remain 2m 9s) Loss: 0.3119(0.3119) \n",
      "EVAL: [100/124] Data 0.000 (0.027) Elapsed 0m 13s (remain 0m 3s) Loss: 0.1759(0.2923) \n",
      "EVAL: [123/124] Data 0.000 (0.024) Elapsed 0m 15s (remain 0m 0s) Loss: 0.5082(0.2932) \n",
      "weight = 1 evaluation score = 0.6051208972930908\n",
      "weight = 2 evaluation score = 0.5272835493087769\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - avg_train_loss: 0.3244  time: 186s\n",
      "Epoch 20 - avg_val_loss: 0.2932 - avg_val_bce: 0.2800 - avg_val_comp_metric : 0.6193 - w_avg_val_comp_metric : 0.6082\n",
      "***** Epoch 21 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:19, scheduler_lr:1.920329799623685e-05\n",
      "optimizer_lr:1.920329799623685e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4635095209929564 0.6551026514413429 0.7517918957226359 0.2787650845272079\n",
      "w1 = 1 w2 = 1 0.5372922881710358\n",
      "0.44549012841287833 0.6561032481878195 0.6937193311853753 0.2655745779956612\n",
      "w1 = 2 w2 = 4 0.5152218214454336\n",
      "Epoch: [21][0/371] Data 1.994 (1.994) Elapsed 0m 2s (remain 14m 23s) Loss: 0.3198(0.3198) Grad: 0.0000  LR: 0.0000192  \n",
      "tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [21][100/371] Data 0.000 (0.048) Elapsed 0m 38s (remain 1m 42s) Loss: 0.3408(0.3457) Grad: 0.0000  LR: 0.0000192  \n",
      "Epoch: [21][200/371] Data 0.000 (0.027) Elapsed 1m 11s (remain 1m 0s) Loss: 0.4933(0.3307) Grad: 0.0000  LR: 0.0000192  \n",
      "Epoch: [21][300/371] Data 0.000 (0.018) Elapsed 1m 44s (remain 0m 24s) Loss: 0.1267(0.3266) Grad: 0.0000  LR: 0.0000192  \n",
      "Epoch: [21][370/371] Data 0.000 (0.015) Elapsed 2m 7s (remain 0m 0s) Loss: 0.5614(0.3256) Grad: 0.0000  LR: 0.0000192  \n",
      "EVAL: [0/124] Data 1.035 (1.035) Elapsed 0m 1s (remain 2m 20s) Loss: 0.2940(0.2940) \n",
      "EVAL: [100/124] Data 0.000 (0.036) Elapsed 0m 14s (remain 0m 3s) Loss: 0.2337(0.2928) \n",
      "EVAL: [123/124] Data 0.000 (0.043) Elapsed 0m 18s (remain 0m 0s) Loss: 0.4647(0.2929) \n",
      "weight = 1 evaluation score = 0.5530427694320679\n",
      "weight = 2 evaluation score = 0.5089199542999268\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - avg_train_loss: 0.3256  time: 146s\n",
      "Epoch 21 - avg_val_loss: 0.2929 - avg_val_bce: 0.2864 - avg_val_comp_metric : 0.5978 - w_avg_val_comp_metric : 0.6120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42392185042312913 0.6775899336533698 0.7273244922570834 0.241831109112575\n",
      "w1 = 1 w2 = 1 0.5176668463615394\n",
      "0.48256734410814134 0.6507594691136132 0.7132042531708664 0.27453595592383606\n",
      "w1 = 2 w2 = 4 0.5302667555791143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 22 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:20, scheduler_lr:1.751599449604977e-05\n",
      "optimizer_lr:1.751599449604977e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [22][0/371] Data 1.651 (1.651) Elapsed 0m 1s (remain 12m 13s) Loss: 0.3391(0.3391) Grad: 0.0000  LR: 0.0000175  \n",
      "tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [22][100/371] Data 0.000 (0.029) Elapsed 0m 36s (remain 1m 36s) Loss: 0.3027(0.3187) Grad: 0.0000  LR: 0.0000175  \n",
      "Epoch: [22][200/371] Data 0.000 (0.015) Elapsed 1m 9s (remain 0m 58s) Loss: 0.2742(0.3147) Grad: 0.0000  LR: 0.0000175  \n",
      "Epoch: [22][300/371] Data 0.000 (0.010) Elapsed 1m 42s (remain 0m 23s) Loss: 0.5289(0.3173) Grad: 0.0000  LR: 0.0000175  \n",
      "Epoch: [22][370/371] Data 0.000 (0.008) Elapsed 2m 4s (remain 0m 0s) Loss: 0.2449(0.3195) Grad: 0.0000  LR: 0.0000175  \n",
      "EVAL: [0/124] Data 1.101 (1.101) Elapsed 0m 1s (remain 2m 28s) Loss: 0.2682(0.2682) \n",
      "EVAL: [100/124] Data 0.000 (0.042) Elapsed 0m 14s (remain 0m 3s) Loss: 0.2523(0.2915) \n",
      "EVAL: [123/124] Data 0.000 (0.039) Elapsed 0m 17s (remain 0m 0s) Loss: 0.4623(0.2914) \n",
      "weight = 1 evaluation score = 0.5231600999832153\n",
      "weight = 2 evaluation score = 0.5081329941749573\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - avg_train_loss: 0.3195  time: 146s\n",
      "Epoch 22 - avg_val_loss: 0.2914 - avg_val_bce: 0.2970 - avg_val_comp_metric : 0.5908 - w_avg_val_comp_metric : 0.6274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4107591590794617 0.6620408243676731 0.7105361589532653 0.2383302038240292\n",
      "w1 = 1 w2 = 1 0.5054165865561073\n",
      "0.4786362702692672 0.6819193724599643 0.7449943909197823 0.30835742837673036\n",
      "w1 = 2 w2 = 4 0.553476865506436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 23 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:21, scheduler_lr:1.5846948563585264e-05\n",
      "optimizer_lr:1.5846948563585264e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [23][0/371] Data 2.021 (2.021) Elapsed 0m 2s (remain 14m 32s) Loss: 0.6158(0.6158) Grad: 0.0000  LR: 0.0000158  \n",
      "tensor(0.6158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [23][100/371] Data 0.663 (0.119) Elapsed 0m 45s (remain 2m 1s) Loss: 0.2985(0.3181) Grad: 0.0000  LR: 0.0000158  \n",
      "Epoch: [23][200/371] Data 0.136 (0.135) Elapsed 1m 33s (remain 1m 19s) Loss: 0.5022(0.3227) Grad: 0.0000  LR: 0.0000158  \n",
      "Epoch: [23][300/371] Data 0.000 (0.116) Elapsed 2m 14s (remain 0m 31s) Loss: 0.4884(0.3216) Grad: 0.0000  LR: 0.0000158  \n",
      "Epoch: [23][370/371] Data 0.000 (0.100) Elapsed 2m 39s (remain 0m 0s) Loss: 0.4500(0.3194) Grad: 0.0000  LR: 0.0000158  \n",
      "EVAL: [0/124] Data 0.924 (0.924) Elapsed 0m 1s (remain 2m 6s) Loss: 0.3205(0.3205) \n",
      "EVAL: [100/124] Data 0.000 (0.074) Elapsed 0m 17s (remain 0m 4s) Loss: 0.1820(0.2890) \n",
      "EVAL: [123/124] Data 0.000 (0.064) Elapsed 0m 20s (remain 0m 0s) Loss: 0.5265(0.2903) \n",
      "weight = 1 evaluation score = 0.5872368216514587\n",
      "weight = 2 evaluation score = 0.511265754699707\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - avg_train_loss: 0.3194  time: 181s\n",
      "Epoch 23 - avg_val_loss: 0.2903 - avg_val_bce: 0.2735 - avg_val_comp_metric : 0.5995 - w_avg_val_comp_metric : 0.5879\n",
      "***** Epoch 24 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:22, scheduler_lr:1.4208185713032831e-05\n",
      "optimizer_lr:1.4208185713032831e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44615447098033845 0.660812092918453 0.7366352232323389 0.2549493845663247\n",
      "w1 = 1 w2 = 1 0.5246377929243639\n",
      "0.4358343803912802 0.63066053405152 0.6881555388289877 0.2502889562531168\n",
      "w1 = 2 w2 = 4 0.5012348523812262\n",
      "Epoch: [24][0/371] Data 2.053 (2.053) Elapsed 0m 2s (remain 14m 45s) Loss: 0.2847(0.2847) Grad: 0.0000  LR: 0.0000142  \n",
      "tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [24][100/371] Data 0.000 (0.024) Elapsed 0m 35s (remain 1m 35s) Loss: 0.7135(0.3169) Grad: 0.0000  LR: 0.0000142  \n",
      "Epoch: [24][200/371] Data 0.000 (0.012) Elapsed 1m 8s (remain 0m 58s) Loss: 0.3828(0.3159) Grad: 0.0000  LR: 0.0000142  \n",
      "Epoch: [24][300/371] Data 0.000 (0.009) Elapsed 1m 41s (remain 0m 23s) Loss: 0.3817(0.3186) Grad: 0.0000  LR: 0.0000142  \n",
      "Epoch: [24][370/371] Data 0.000 (0.007) Elapsed 2m 4s (remain 0m 0s) Loss: 0.1129(0.3191) Grad: 0.0000  LR: 0.0000142  \n",
      "EVAL: [0/124] Data 1.282 (1.282) Elapsed 0m 1s (remain 2m 50s) Loss: 0.2803(0.2803) \n",
      "EVAL: [100/124] Data 0.000 (0.058) Elapsed 0m 16s (remain 0m 3s) Loss: 0.2187(0.2847) \n",
      "EVAL: [123/124] Data 0.000 (0.054) Elapsed 0m 19s (remain 0m 0s) Loss: 0.4679(0.2851) \n",
      "weight = 1 evaluation score = 0.5400829315185547\n",
      "weight = 2 evaluation score = 0.4994826912879944\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - avg_train_loss: 0.3191  time: 145s\n",
      "Epoch 24 - avg_val_loss: 0.2851 - avg_val_bce: 0.2813 - avg_val_comp_metric : 0.5883 - w_avg_val_comp_metric : 0.6087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4198465152337722 0.648150262138491 0.706940385163212 0.24729541351921677\n",
      "w1 = 1 w2 = 1 0.505558144013673\n",
      "0.4519370109454487 0.6640158974569664 0.6994301275029864 0.29544363115086997\n",
      "w1 = 2 w2 = 4 0.5277066667640679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 25 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:23, scheduler_lr:1.2611513268282851e-05\n",
      "optimizer_lr:1.2611513268282851e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [25][0/371] Data 1.676 (1.676) Elapsed 0m 2s (remain 12m 23s) Loss: 0.2460(0.2460) Grad: 0.0000  LR: 0.0000126  \n",
      "tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [25][100/371] Data 0.000 (0.036) Elapsed 0m 36s (remain 1m 38s) Loss: 0.1539(0.3238) Grad: 0.0000  LR: 0.0000126  \n",
      "Epoch: [25][200/371] Data 0.000 (0.021) Elapsed 1m 10s (remain 0m 59s) Loss: 0.2917(0.3252) Grad: 0.0000  LR: 0.0000126  \n",
      "Epoch: [25][300/371] Data 0.000 (0.014) Elapsed 1m 43s (remain 0m 24s) Loss: 0.3633(0.3207) Grad: 0.0000  LR: 0.0000126  \n",
      "Epoch: [25][370/371] Data 0.000 (0.012) Elapsed 2m 6s (remain 0m 0s) Loss: 0.4959(0.3196) Grad: 0.0000  LR: 0.0000126  \n",
      "EVAL: [0/124] Data 0.928 (0.928) Elapsed 0m 1s (remain 2m 7s) Loss: 0.2620(0.2620) \n",
      "EVAL: [100/124] Data 0.485 (0.038) Elapsed 0m 14s (remain 0m 3s) Loss: 0.2292(0.2809) \n",
      "EVAL: [123/124] Data 0.000 (0.032) Elapsed 0m 16s (remain 0m 0s) Loss: 0.4679(0.2816) \n",
      "weight = 1 evaluation score = 0.519325852394104\n",
      "weight = 2 evaluation score = 0.486311137676239\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - avg_train_loss: 0.3196  time: 144s\n",
      "Epoch 25 - avg_val_loss: 0.2816 - avg_val_bce: 0.2796 - avg_val_comp_metric : 0.5733 - w_avg_val_comp_metric : 0.5959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39613140771900185 0.6456346636506298 0.6982312927172619 0.23191196091338223\n",
      "w1 = 1 w2 = 1 0.492977331250069\n",
      "0.4409083600163803 0.6481914401405531 0.698841393780732 0.2831102634231226\n",
      "w1 = 2 w2 = 4 0.517762864340197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 26 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:24, scheduler_lr:1.106843529088742e-05\n",
      "optimizer_lr:1.106843529088742e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [26][0/371] Data 1.589 (1.589) Elapsed 0m 1s (remain 11m 51s) Loss: 0.1406(0.1406) Grad: 0.0000  LR: 0.0000111  \n",
      "tensor(0.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [26][100/371] Data 0.000 (0.032) Elapsed 0m 36s (remain 1m 37s) Loss: 0.3003(0.3262) Grad: 0.0000  LR: 0.0000111  \n",
      "Epoch: [26][200/371] Data 0.000 (0.016) Elapsed 1m 9s (remain 0m 58s) Loss: 0.3469(0.3219) Grad: 0.0000  LR: 0.0000111  \n",
      "Epoch: [26][300/371] Data 0.080 (0.016) Elapsed 1m 43s (remain 0m 24s) Loss: 0.2307(0.3131) Grad: 0.0000  LR: 0.0000111  \n",
      "Epoch: [26][370/371] Data 0.000 (0.015) Elapsed 2m 7s (remain 0m 0s) Loss: 0.2884(0.3142) Grad: 0.0000  LR: 0.0000111  \n",
      "EVAL: [0/124] Data 1.193 (1.193) Elapsed 0m 1s (remain 2m 40s) Loss: 0.2680(0.2680) \n",
      "EVAL: [100/124] Data 0.000 (0.043) Elapsed 0m 14s (remain 0m 3s) Loss: 0.2129(0.2835) \n",
      "EVAL: [123/124] Data 0.000 (0.038) Elapsed 0m 17s (remain 0m 0s) Loss: 0.4729(0.2843) \n",
      "weight = 1 evaluation score = 0.540757417678833\n",
      "weight = 2 evaluation score = 0.49400484561920166\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 - avg_train_loss: 0.3142  time: 146s\n",
      "Epoch 26 - avg_val_loss: 0.2843 - avg_val_bce: 0.2770 - avg_val_comp_metric : 0.5815 - w_avg_val_comp_metric : 0.5952\n",
      "***** Epoch 27 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:25, scheduler_lr:9.590069693033237e-06\n",
      "optimizer_lr:9.590069693033237e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41297740352828777 0.657667226743254 0.7022477660203644 0.2425963675938028\n",
      "w1 = 1 w2 = 1 0.5038721909714272\n",
      "0.443915336266985 0.6431016214396016 0.688384688921735 0.286384481998244\n",
      "w1 = 2 w2 = 4 0.5154465321566414\n",
      "Epoch: [27][0/371] Data 1.455 (1.455) Elapsed 0m 1s (remain 11m 1s) Loss: 0.3245(0.3245) Grad: 0.0000  LR: 0.0000096  \n",
      "tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [27][100/371] Data 0.000 (0.034) Elapsed 0m 36s (remain 1m 38s) Loss: 0.4856(0.3224) Grad: 0.0000  LR: 0.0000096  \n",
      "Epoch: [27][200/371] Data 0.000 (0.052) Elapsed 1m 17s (remain 1m 5s) Loss: 0.2219(0.3264) Grad: 0.0000  LR: 0.0000096  \n",
      "Epoch: [27][300/371] Data 0.000 (0.051) Elapsed 1m 54s (remain 0m 26s) Loss: 0.1309(0.3164) Grad: 0.0000  LR: 0.0000096  \n",
      "Epoch: [27][370/371] Data 0.001 (0.056) Elapsed 2m 23s (remain 0m 0s) Loss: 0.3892(0.3175) Grad: 0.0000  LR: 0.0000096  \n",
      "EVAL: [0/124] Data 1.010 (1.010) Elapsed 0m 1s (remain 2m 17s) Loss: 0.2706(0.2706) \n",
      "EVAL: [100/124] Data 0.000 (0.032) Elapsed 0m 13s (remain 0m 3s) Loss: 0.2176(0.2790) \n",
      "EVAL: [123/124] Data 0.000 (0.031) Elapsed 0m 16s (remain 0m 0s) Loss: 0.4922(0.2798) \n",
      "weight = 1 evaluation score = 0.5132099986076355\n",
      "weight = 2 evaluation score = 0.4793519973754883\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 - avg_train_loss: 0.3175  time: 163s\n",
      "Epoch 27 - avg_val_loss: 0.2798 - avg_val_bce: 0.2784 - avg_val_comp_metric : 0.5671 - w_avg_val_comp_metric : 0.5873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3852964712800954 0.6491705429146302 0.7036127610464306 0.22393939735490526\n",
      "w1 = 1 w2 = 1 0.49050479314901535\n",
      "0.4215037436168295 0.6561000965279887 0.6945006610713208 0.2787467047183357\n",
      "w1 = 2 w2 = 4 0.5127128014836186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Epoch 28 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:26, scheduler_lr:8.187068132729488e-06\n",
      "optimizer_lr:8.187068132729488e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [28][0/371] Data 2.340 (2.340) Elapsed 0m 2s (remain 16m 33s) Loss: 0.3171(0.3171) Grad: 0.0000  LR: 0.0000082  \n",
      "tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [28][100/371] Data 0.000 (0.039) Elapsed 0m 37s (remain 1m 39s) Loss: 0.2452(0.3213) Grad: 0.0000  LR: 0.0000082  \n",
      "Epoch: [28][200/371] Data 0.000 (0.020) Elapsed 1m 10s (remain 0m 59s) Loss: 0.2399(0.3145) Grad: 0.0000  LR: 0.0000082  \n",
      "Epoch: [28][300/371] Data 0.000 (0.013) Elapsed 1m 43s (remain 0m 24s) Loss: 0.1866(0.3142) Grad: 0.0000  LR: 0.0000082  \n",
      "Epoch: [28][370/371] Data 0.000 (0.011) Elapsed 2m 6s (remain 0m 0s) Loss: 0.0407(0.3139) Grad: 0.0000  LR: 0.0000082  \n",
      "EVAL: [0/124] Data 0.924 (0.924) Elapsed 0m 1s (remain 2m 6s) Loss: 0.2930(0.2930) \n",
      "EVAL: [100/124] Data 0.001 (0.019) Elapsed 0m 12s (remain 0m 2s) Loss: 0.2090(0.2838) \n",
      "EVAL: [123/124] Data 0.000 (0.022) Elapsed 0m 15s (remain 0m 0s) Loss: 0.5068(0.2842) \n",
      "weight = 1 evaluation score = 0.5604969263076782\n",
      "weight = 2 evaluation score = 0.5022704601287842\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 - avg_train_loss: 0.3139  time: 142s\n",
      "Epoch 28 - avg_val_loss: 0.2842 - avg_val_bce: 0.2770 - avg_val_comp_metric : 0.5942 - w_avg_val_comp_metric : 0.5989\n",
      "***** Epoch 29 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:27, scheduler_lr:6.869539268367882e-06\n",
      "optimizer_lr:6.869539268367882e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42443524945814165 0.6511649066692532 0.7256727869577088 0.2542097806260858\n",
      "w1 = 1 w2 = 1 0.5138706809277974\n",
      "0.43222759161928875 0.6508813330311078 0.6912640289432158 0.278514262120595\n",
      "w1 = 2 w2 = 4 0.5132218039285519\n",
      "Epoch: [29][0/371] Data 1.573 (1.573) Elapsed 0m 1s (remain 11m 45s) Loss: 0.1471(0.1471) Grad: 0.0000  LR: 0.0000069  \n",
      "tensor(0.1471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [29][100/371] Data 0.139 (0.055) Elapsed 0m 38s (remain 1m 43s) Loss: 0.2516(0.3229) Grad: 0.0000  LR: 0.0000069  \n",
      "Epoch: [29][200/371] Data 0.000 (0.046) Elapsed 1m 15s (remain 1m 3s) Loss: 0.2691(0.3156) Grad: 0.0000  LR: 0.0000069  \n",
      "Epoch: [29][300/371] Data 0.000 (0.041) Elapsed 1m 51s (remain 0m 26s) Loss: 0.3673(0.3140) Grad: 0.0000  LR: 0.0000069  \n",
      "Epoch: [29][370/371] Data 0.000 (0.035) Elapsed 2m 14s (remain 0m 0s) Loss: 0.2050(0.3166) Grad: 0.0000  LR: 0.0000069  \n",
      "EVAL: [0/124] Data 0.830 (0.830) Elapsed 0m 0s (remain 1m 55s) Loss: 0.2839(0.2839) \n",
      "EVAL: [100/124] Data 0.000 (0.054) Elapsed 0m 15s (remain 0m 3s) Loss: 0.2332(0.2818) \n",
      "EVAL: [123/124] Data 0.000 (0.051) Elapsed 0m 19s (remain 0m 0s) Loss: 0.4666(0.2820) \n",
      "weight = 1 evaluation score = 0.5276989340782166\n",
      "weight = 2 evaluation score = 0.48888128995895386\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 - avg_train_loss: 0.3166  time: 155s\n",
      "Epoch 29 - avg_val_loss: 0.2820 - avg_val_bce: 0.2790 - avg_val_comp_metric : 0.5786 - w_avg_val_comp_metric : 0.5986\n",
      "***** Epoch 30 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:28, scheduler_lr:5.646975925607241e-06\n",
      "optimizer_lr:5.646975925607241e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3996651064173348 0.6494145104737052 0.7016319716131888 0.23764040823989716\n",
      "w1 = 1 w2 = 1 0.49708799918603147\n",
      "0.44012614438645853 0.6506401972550897 0.6964113123831269 0.28478581749463994\n",
      "w1 = 2 w2 = 4 0.5179908678798287\n",
      "Epoch: [30][0/371] Data 1.959 (1.959) Elapsed 0m 2s (remain 14m 7s) Loss: 0.2001(0.2001) Grad: 0.0000  LR: 0.0000056  \n",
      "tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [30][100/371] Data 0.000 (0.028) Elapsed 0m 36s (remain 1m 36s) Loss: 0.4258(0.3093) Grad: 0.0000  LR: 0.0000056  \n",
      "Epoch: [30][200/371] Data 0.000 (0.017) Elapsed 1m 9s (remain 0m 58s) Loss: 0.4668(0.3144) Grad: 0.0000  LR: 0.0000056  \n",
      "Epoch: [30][300/371] Data 0.000 (0.011) Elapsed 1m 42s (remain 0m 23s) Loss: 0.3094(0.3082) Grad: 0.0000  LR: 0.0000056  \n",
      "Epoch: [30][370/371] Data 0.000 (0.009) Elapsed 2m 5s (remain 0m 0s) Loss: 0.3871(0.3077) Grad: 0.0000  LR: 0.0000056  \n",
      "EVAL: [0/124] Data 1.068 (1.068) Elapsed 0m 1s (remain 2m 24s) Loss: 0.2922(0.2922) \n",
      "EVAL: [100/124] Data 0.030 (0.066) Elapsed 0m 17s (remain 0m 3s) Loss: 0.2139(0.2805) \n",
      "EVAL: [123/124] Data 0.000 (0.068) Elapsed 0m 21s (remain 0m 0s) Loss: 0.4713(0.2810) \n",
      "weight = 1 evaluation score = 0.534194827079773\n",
      "weight = 2 evaluation score = 0.4859338104724884\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 - avg_train_loss: 0.3077  time: 147s\n",
      "Epoch 30 - avg_val_loss: 0.2810 - avg_val_bce: 0.2720 - avg_val_comp_metric : 0.5733 - w_avg_val_comp_metric : 0.5843\n",
      "***** Epoch 31 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:29, scheduler_lr:4.528186701347132e-06\n",
      "optimizer_lr:4.528186701347132e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40006592449847406 0.6486039453776526 0.70712172265937 0.2376592926392154\n",
      "w1 = 1 w2 = 1 0.49836272129367803\n",
      "0.42969403326600525 0.6337158848719537 0.6763469835565936 0.28455942200837253\n",
      "w1 = 2 w2 = 4 0.5060790809257313\n",
      "Epoch: [31][0/371] Data 2.158 (2.158) Elapsed 0m 2s (remain 15m 21s) Loss: 0.4109(0.4109) Grad: 0.0000  LR: 0.0000045  \n",
      "tensor(0.4109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [31][100/371] Data 0.000 (0.045) Elapsed 0m 37s (remain 1m 41s) Loss: 0.3004(0.3200) Grad: 0.0000  LR: 0.0000045  \n",
      "Epoch: [31][200/371] Data 0.000 (0.061) Elapsed 1m 18s (remain 1m 6s) Loss: 0.3650(0.3122) Grad: 0.0000  LR: 0.0000045  \n",
      "Epoch: [31][300/371] Data 0.000 (0.068) Elapsed 1m 59s (remain 0m 27s) Loss: 0.3873(0.3109) Grad: 0.0000  LR: 0.0000045  \n",
      "Epoch: [31][370/371] Data 0.000 (0.055) Elapsed 2m 22s (remain 0m 0s) Loss: 0.2213(0.3141) Grad: 0.0000  LR: 0.0000045  \n",
      "EVAL: [0/124] Data 1.611 (1.611) Elapsed 0m 1s (remain 3m 31s) Loss: 0.2890(0.2890) \n",
      "EVAL: [100/124] Data 0.000 (0.072) Elapsed 0m 17s (remain 0m 4s) Loss: 0.2220(0.2824) \n",
      "EVAL: [123/124] Data 0.000 (0.065) Elapsed 0m 20s (remain 0m 0s) Loss: 0.4737(0.2832) \n",
      "weight = 1 evaluation score = 0.5239279866218567\n",
      "weight = 2 evaluation score = 0.48102790117263794\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 - avg_train_loss: 0.3141  time: 164s\n",
      "Epoch 31 - avg_val_loss: 0.2832 - avg_val_bce: 0.2721 - avg_val_comp_metric : 0.5647 - w_avg_val_comp_metric : 0.5789\n",
      "***** Epoch 32 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:30, scheduler_lr:3.5212324975853526e-06\n",
      "optimizer_lr:3.5212324975853526e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3905361062986696 0.6575684731972347 0.7046748964353261 0.22586287684092252\n",
      "w1 = 1 w2 = 1 0.4946605881930382\n",
      "0.427346054582833 0.6329515635445755 0.6784124948033929 0.2815473660085573\n",
      "w1 = 2 w2 = 4 0.5050643697348397\n",
      "Epoch: [32][0/371] Data 1.544 (1.544) Elapsed 0m 1s (remain 11m 33s) Loss: 0.2621(0.2621) Grad: 0.0000  LR: 0.0000035  \n",
      "tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [32][100/371] Data 0.000 (0.041) Elapsed 0m 37s (remain 1m 40s) Loss: 0.4373(0.3131) Grad: 0.0000  LR: 0.0000035  \n",
      "Epoch: [32][200/371] Data 0.000 (0.021) Elapsed 1m 10s (remain 0m 59s) Loss: 0.1470(0.3041) Grad: 0.0000  LR: 0.0000035  \n",
      "Epoch: [32][300/371] Data 0.000 (0.017) Elapsed 1m 44s (remain 0m 24s) Loss: 0.3060(0.3031) Grad: 0.0000  LR: 0.0000035  \n",
      "Epoch: [32][370/371] Data 0.000 (0.020) Elapsed 2m 9s (remain 0m 0s) Loss: 0.3737(0.3042) Grad: 0.0000  LR: 0.0000035  \n",
      "EVAL: [0/124] Data 0.917 (0.917) Elapsed 0m 1s (remain 2m 6s) Loss: 0.2743(0.2743) \n",
      "EVAL: [100/124] Data 0.000 (0.030) Elapsed 0m 13s (remain 0m 3s) Loss: 0.2371(0.2803) \n",
      "EVAL: [123/124] Data 0.000 (0.026) Elapsed 0m 16s (remain 0m 0s) Loss: 0.4519(0.2807) \n",
      "weight = 1 evaluation score = 0.513982892036438\n",
      "weight = 2 evaluation score = 0.4833054840564728\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 - avg_train_loss: 0.3042  time: 148s\n",
      "Epoch 32 - avg_val_loss: 0.2807 - avg_val_bce: 0.2788 - avg_val_comp_metric : 0.5699 - w_avg_val_comp_metric : 0.5938\n",
      "***** Epoch 33 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:31, scheduler_lr:2.6333684424343023e-06\n",
      "optimizer_lr:2.6333684424343023e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3950737213950877 0.64081655071457 0.6913888674125511 0.23170105150343945\n",
      "w1 = 1 w2 = 1 0.48974504775641203\n",
      "0.4393570741429208 0.6491957798786389 0.6959744164794675 0.2882956983560064\n",
      "w1 = 2 w2 = 4 0.5182057422142584\n",
      "Epoch: [33][0/371] Data 2.007 (2.007) Elapsed 0m 2s (remain 14m 26s) Loss: 0.1925(0.1925) Grad: 0.0000  LR: 0.0000026  \n",
      "tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [33][100/371] Data 0.000 (0.058) Elapsed 0m 39s (remain 1m 44s) Loss: 0.3715(0.2999) Grad: 0.0000  LR: 0.0000026  \n",
      "Epoch: [33][200/371] Data 0.023 (0.043) Elapsed 1m 15s (remain 1m 3s) Loss: 0.3482(0.3119) Grad: 0.0000  LR: 0.0000026  \n",
      "Epoch: [33][300/371] Data 0.000 (0.041) Elapsed 1m 51s (remain 0m 26s) Loss: 0.2459(0.3094) Grad: 0.0000  LR: 0.0000026  \n",
      "Epoch: [33][370/371] Data 0.000 (0.040) Elapsed 2m 17s (remain 0m 0s) Loss: 0.3284(0.3080) Grad: 0.0000  LR: 0.0000026  \n",
      "EVAL: [0/124] Data 1.032 (1.032) Elapsed 0m 1s (remain 2m 20s) Loss: 0.2879(0.2879) \n",
      "EVAL: [100/124] Data 0.000 (0.031) Elapsed 0m 13s (remain 0m 3s) Loss: 0.2041(0.2807) \n",
      "EVAL: [123/124] Data 0.000 (0.025) Elapsed 0m 16s (remain 0m 0s) Loss: 0.4759(0.2811) \n",
      "weight = 1 evaluation score = 0.5370829105377197\n",
      "weight = 2 evaluation score = 0.4876065254211426\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 - avg_train_loss: 0.3080  time: 154s\n",
      "Epoch 33 - avg_val_loss: 0.2811 - avg_val_bce: 0.2745 - avg_val_comp_metric : 0.5784 - w_avg_val_comp_metric : 0.5902\n",
      "***** Epoch 34 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:32, scheduler_lr:1.870991616756696e-06\n",
      "optimizer_lr:1.870991616756696e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40665479603455174 0.6474304432621496 0.7114008911483349 0.238252375694086\n",
      "w1 = 1 w2 = 1 0.5009346265347806\n",
      "0.43030011389555195 0.6416656159798062 0.6827507997429452 0.2814006043489358\n",
      "w1 = 2 w2 = 4 0.5090292834918098\n",
      "Epoch: [34][0/371] Data 2.243 (2.243) Elapsed 0m 2s (remain 15m 53s) Loss: 0.1125(0.1125) Grad: 0.0000  LR: 0.0000019  \n",
      "tensor(0.1125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [34][100/371] Data 0.000 (0.034) Elapsed 0m 36s (remain 1m 38s) Loss: 0.2450(0.3205) Grad: 0.0000  LR: 0.0000019  \n",
      "Epoch: [34][200/371] Data 0.000 (0.017) Elapsed 1m 10s (remain 0m 59s) Loss: 0.3097(0.3114) Grad: 0.0000  LR: 0.0000019  \n",
      "Epoch: [34][300/371] Data 0.000 (0.012) Elapsed 1m 43s (remain 0m 23s) Loss: 0.3663(0.3128) Grad: 0.0000  LR: 0.0000019  \n",
      "Epoch: [34][370/371] Data 0.000 (0.009) Elapsed 2m 5s (remain 0m 0s) Loss: 0.2522(0.3086) Grad: 0.0000  LR: 0.0000019  \n",
      "EVAL: [0/124] Data 1.009 (1.009) Elapsed 0m 1s (remain 2m 17s) Loss: 0.2814(0.2814) \n",
      "EVAL: [100/124] Data 0.311 (0.062) Elapsed 0m 16s (remain 0m 3s) Loss: 0.2222(0.2784) \n",
      "EVAL: [123/124] Data 0.000 (0.061) Elapsed 0m 20s (remain 0m 0s) Loss: 0.4660(0.2785) \n",
      "weight = 1 evaluation score = 0.5167585611343384\n",
      "weight = 2 evaluation score = 0.48034200072288513\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 - avg_train_loss: 0.3086  time: 150s\n",
      "Epoch 34 - avg_val_loss: 0.2785 - avg_val_bce: 0.2763 - avg_val_comp_metric : 0.5693 - w_avg_val_comp_metric : 0.5899\n",
      "***** Epoch 35 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:33, scheduler_lr:1.2395949630513709e-06\n",
      "optimizer_lr:1.2395949630513709e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39171829686230725 0.6384557319079793 0.6969056009173846 0.23058253810729792\n",
      "w1 = 1 w2 = 1 0.48941554194874226\n",
      "0.42657787568946876 0.6496577678891546 0.6883295453410639 0.280850543874454\n",
      "w1 = 2 w2 = 4 0.5113539331985353\n",
      "Epoch: [35][0/371] Data 2.255 (2.255) Elapsed 0m 2s (remain 16m 1s) Loss: 0.3646(0.3646) Grad: 0.0000  LR: 0.0000012  \n",
      "tensor(0.3646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [35][100/371] Data 0.000 (0.078) Elapsed 0m 41s (remain 1m 50s) Loss: 0.3628(0.3021) Grad: 0.0000  LR: 0.0000012  \n",
      "Epoch: [35][200/371] Data 0.000 (0.039) Elapsed 1m 14s (remain 1m 2s) Loss: 0.3242(0.2966) Grad: 0.0000  LR: 0.0000012  \n",
      "Epoch: [35][300/371] Data 0.000 (0.026) Elapsed 1m 47s (remain 0m 24s) Loss: 0.1041(0.3052) Grad: 0.0000  LR: 0.0000012  \n",
      "Epoch: [35][370/371] Data 0.000 (0.023) Elapsed 2m 10s (remain 0m 0s) Loss: 0.1066(0.3062) Grad: 0.0000  LR: 0.0000012  \n",
      "EVAL: [0/124] Data 1.082 (1.082) Elapsed 0m 1s (remain 2m 25s) Loss: 0.2907(0.2907) \n",
      "EVAL: [100/124] Data 0.000 (0.051) Elapsed 0m 15s (remain 0m 3s) Loss: 0.2192(0.2794) \n",
      "EVAL: [123/124] Data 0.000 (0.044) Elapsed 0m 18s (remain 0m 0s) Loss: 0.4688(0.2797) \n",
      "weight = 1 evaluation score = 0.5265325903892517\n",
      "weight = 2 evaluation score = 0.48054036498069763\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 - avg_train_loss: 0.3062  time: 150s\n",
      "Epoch 35 - avg_val_loss: 0.2797 - avg_val_bce: 0.2734 - avg_val_comp_metric : 0.5692 - w_avg_val_comp_metric : 0.5802\n",
      "***** Epoch 36 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:34, scheduler_lr:7.437277086766979e-07\n",
      "optimizer_lr:7.437277086766979e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3950268154792734 0.6452700067467085 0.7029201439790926 0.2293678416958564\n",
      "w1 = 1 w2 = 1 0.49314620197523273\n",
      "0.4191927661413205 0.6363108307205 0.683359159671422 0.2668640461912827\n",
      "w1 = 2 w2 = 4 0.5014317006811313\n",
      "Epoch: [36][0/371] Data 1.928 (1.928) Elapsed 0m 2s (remain 13m 56s) Loss: 0.2904(0.2904) Grad: 0.0000  LR: 0.0000007  \n",
      "tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [36][100/371] Data 0.000 (0.027) Elapsed 0m 36s (remain 1m 36s) Loss: 0.6546(0.3164) Grad: 0.0000  LR: 0.0000007  \n",
      "Epoch: [36][200/371] Data 0.000 (0.024) Elapsed 1m 10s (remain 0m 59s) Loss: 0.1889(0.3074) Grad: 0.0000  LR: 0.0000007  \n",
      "Epoch: [36][300/371] Data 0.000 (0.018) Elapsed 1m 44s (remain 0m 24s) Loss: 0.2198(0.3143) Grad: 0.0000  LR: 0.0000007  \n",
      "Epoch: [36][370/371] Data 0.000 (0.014) Elapsed 2m 6s (remain 0m 0s) Loss: 0.1646(0.3109) Grad: 0.0000  LR: 0.0000007  \n",
      "EVAL: [0/124] Data 0.860 (0.860) Elapsed 0m 0s (remain 1m 58s) Loss: 0.2871(0.2871) \n",
      "EVAL: [100/124] Data 0.000 (0.014) Elapsed 0m 11s (remain 0m 2s) Loss: 0.2165(0.2795) \n",
      "EVAL: [123/124] Data 0.000 (0.012) Elapsed 0m 14s (remain 0m 0s) Loss: 0.4662(0.2797) \n",
      "weight = 1 evaluation score = 0.5248975157737732\n",
      "weight = 2 evaluation score = 0.4798615574836731\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 - avg_train_loss: 0.3109  time: 142s\n",
      "Epoch 36 - avg_val_loss: 0.2797 - avg_val_bce: 0.2731 - avg_val_comp_metric : 0.5686 - w_avg_val_comp_metric : 0.5811\n",
      "***** Epoch 37 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:35, scheduler_lr:3.8696258856321644e-07\n",
      "optimizer_lr:3.8696258856321644e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39466521002516985 0.6451837911622225 0.7006143656413315 0.2290379961691642\n",
      "w1 = 1 w2 = 1 0.492375340749472\n",
      "0.4212305904867738 0.6361957447746177 0.681860110263621 0.268811018270642\n",
      "w1 = 2 w2 = 4 0.5020243659489136\n",
      "Epoch: [37][0/371] Data 2.517 (2.517) Elapsed 0m 2s (remain 17m 35s) Loss: 0.2009(0.2009) Grad: 0.0000  LR: 0.0000004  \n",
      "tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [37][100/371] Data 0.000 (0.036) Elapsed 0m 36s (remain 1m 38s) Loss: 0.1890(0.3189) Grad: 0.0000  LR: 0.0000004  \n",
      "Epoch: [37][200/371] Data 0.000 (0.023) Elapsed 1m 10s (remain 0m 59s) Loss: 0.1895(0.3191) Grad: 0.0000  LR: 0.0000004  \n",
      "Epoch: [37][300/371] Data 0.000 (0.015) Elapsed 1m 43s (remain 0m 24s) Loss: 0.2153(0.3145) Grad: 0.0000  LR: 0.0000004  \n",
      "Epoch: [37][370/371] Data 0.000 (0.012) Elapsed 2m 6s (remain 0m 0s) Loss: 0.9161(0.3091) Grad: 0.0000  LR: 0.0000004  \n",
      "EVAL: [0/124] Data 1.145 (1.145) Elapsed 0m 1s (remain 2m 33s) Loss: 0.2781(0.2781) \n",
      "EVAL: [100/124] Data 0.000 (0.044) Elapsed 0m 14s (remain 0m 3s) Loss: 0.2173(0.2811) \n",
      "EVAL: [123/124] Data 0.000 (0.036) Elapsed 0m 17s (remain 0m 0s) Loss: 0.4628(0.2813) \n",
      "weight = 1 evaluation score = 0.5245867371559143\n",
      "weight = 2 evaluation score = 0.48294922709465027\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 - avg_train_loss: 0.3091  time: 145s\n",
      "Epoch 37 - avg_val_loss: 0.2813 - avg_val_bce: 0.2751 - avg_val_comp_metric : 0.5711 - w_avg_val_comp_metric : 0.5865\n",
      "***** Epoch 38 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:36, scheduler_lr:1.7187010357659594e-07\n",
      "optimizer_lr:1.7187010357659594e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39857374059060785 0.646444783689839 0.7019417980847367 0.23188027783003992\n",
      "w1 = 1 w2 = 1 0.49471015004880586\n",
      "0.43296058792048486 0.6382552006325978 0.6861028620738403 0.27588090854997604\n",
      "w1 = 2 w2 = 4 0.5082998897942248\n",
      "Epoch: [38][0/371] Data 1.507 (1.507) Elapsed 0m 1s (remain 11m 20s) Loss: 0.3745(0.3745) Grad: 0.0000  LR: 0.0000002  \n",
      "tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [38][100/371] Data 0.000 (0.029) Elapsed 0m 36s (remain 1m 36s) Loss: 0.1969(0.2978) Grad: 0.0000  LR: 0.0000002  \n",
      "Epoch: [38][200/371] Data 0.000 (0.016) Elapsed 1m 9s (remain 0m 58s) Loss: 0.2532(0.2959) Grad: 0.0000  LR: 0.0000002  \n",
      "Epoch: [38][300/371] Data 0.000 (0.011) Elapsed 1m 42s (remain 0m 23s) Loss: 0.2591(0.3062) Grad: 0.0000  LR: 0.0000002  \n",
      "Epoch: [38][370/371] Data 0.000 (0.009) Elapsed 2m 5s (remain 0m 0s) Loss: 0.2489(0.3067) Grad: 0.0000  LR: 0.0000002  \n",
      "EVAL: [0/124] Data 1.842 (1.842) Elapsed 0m 1s (remain 3m 59s) Loss: 0.2866(0.2866) \n",
      "EVAL: [100/124] Data 0.000 (0.072) Elapsed 0m 17s (remain 0m 4s) Loss: 0.2185(0.2812) \n",
      "EVAL: [123/124] Data 0.000 (0.066) Elapsed 0m 21s (remain 0m 0s) Loss: 0.4619(0.2815) \n",
      "weight = 1 evaluation score = 0.526309609413147\n",
      "weight = 2 evaluation score = 0.4839579164981842\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 - avg_train_loss: 0.3067  time: 147s\n",
      "Epoch 38 - avg_val_loss: 0.2815 - avg_val_bce: 0.2743 - avg_val_comp_metric : 0.5711 - w_avg_val_comp_metric : 0.5862\n",
      "***** Epoch 39 *****\n",
      "schwarmup_last_epoch:2, schwarmup_lr:4.000000000000001e-05\n",
      "scheduler_last_epoch:37, scheduler_lr:1e-07\n",
      "optimizer_lr:1e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4009922951134894 0.6433457401690706 0.6996266059238587 0.2334318637881063\n",
      "w1 = 1 w2 = 1 0.49434912624863125\n",
      "0.43476630975598646 0.6356988693226345 0.6841678969319956 0.2759693789750132\n",
      "w1 = 2 w2 = 4 0.5076506137464074\n",
      "Epoch: [39][0/371] Data 1.656 (1.656) Elapsed 0m 1s (remain 12m 17s) Loss: 0.2713(0.2713) Grad: 0.0000  LR: 0.0000001  \n",
      "tensor(0.2713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: [39][100/371] Data 0.000 (0.101) Elapsed 0m 43s (remain 1m 56s) Loss: 0.1792(0.3106) Grad: 0.0000  LR: 0.0000001  \n",
      "Epoch: [39][200/371] Data 0.000 (0.083) Elapsed 1m 23s (remain 1m 10s) Loss: 0.2952(0.3121) Grad: 0.0000  LR: 0.0000001  \n",
      "Epoch: [39][300/371] Data 0.131 (0.075) Elapsed 2m 1s (remain 0m 28s) Loss: 0.3181(0.3116) Grad: 0.0000  LR: 0.0000001  \n",
      "Epoch: [39][370/371] Data 0.000 (0.071) Elapsed 2m 28s (remain 0m 0s) Loss: 0.2526(0.3085) Grad: 0.0000  LR: 0.0000001  \n",
      "EVAL: [0/124] Data 1.360 (1.360) Elapsed 0m 1s (remain 3m 0s) Loss: 0.2848(0.2848) \n",
      "EVAL: [100/124] Data 0.000 (0.038) Elapsed 0m 14s (remain 0m 3s) Loss: 0.2242(0.2788) \n",
      "EVAL: [123/124] Data 0.000 (0.034) Elapsed 0m 17s (remain 0m 0s) Loss: 0.4634(0.2789) \n",
      "weight = 1 evaluation score = 0.5184579491615295\n",
      "weight = 2 evaluation score = 0.4770362675189972\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 - avg_train_loss: 0.3085  time: 168s\n",
      "Epoch 39 - avg_val_loss: 0.2789 - avg_val_bce: 0.2733 - avg_val_comp_metric : 0.5642 - w_avg_val_comp_metric : 0.5788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38955084398967416 0.639636316942691 0.6983999890341014 0.22489254977658482\n",
      "w1 = 1 w2 = 1 0.48811992493576284\n",
      "0.4162167944683705 0.6400797028892962 0.6818970555329169 0.2648965948852967\n",
      "w1 = 2 w2 = 4 0.5007725369439701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 1 training ==========\n",
      "***** Epoch 0 *****\n",
      "schwarmup_last_epoch:0, schwarmup_lr:4.000000000000001e-06\n",
      "scheduler_last_epoch:0, scheduler_lr:4.000000000000001e-06\n",
      "optimizer_lr:4.000000000000001e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/371] Data 2.849 (2.849) Elapsed 0m 3s (remain 19m 42s) Loss: 0.8244(0.8244) Grad: 0.0000  LR: 0.0000040  \n",
      "tensor(0.8244, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(CFG.suffix)\n",
    "    if CFG.device == 'TPU':\n",
    "        def _mp_fn(rank, flags):\n",
    "            torch.set_default_tensor_type('torch.FloatTensor')\n",
    "            a = main()\n",
    "        FLAGS = {}\n",
    "        xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=CFG.nprocs, start_method='fork')\n",
    "    elif CFG.device == 'GPU':\n",
    "        oof_list = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
