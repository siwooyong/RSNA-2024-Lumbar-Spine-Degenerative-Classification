{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "datadir = './preprocessed'\n",
    "libdir = '.'\n",
    "outputdir = './output_all'\n",
    "otherdir = '.'\n",
    "train_bs_ = 4\n",
    "valid_bs_ = 4\n",
    "num_workers_ = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i for i in timm.list_models() if 'resnest' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conditions = ['spinal_canal_stenosis', 'left_neural_foraminal_narrowing', 'right_neural_foraminal_narrowing',\n",
    "          'left_subarticular_stenosis', 'right_subarticular_stenosis']\n",
    "levels = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n",
    "severity = ['Normal/Mild', 'Moderate', 'Severe']\n",
    "class CFG:\n",
    "    seed=42\n",
    "    device='GPU'\n",
    "    nprocs=1 # [1, 8]\n",
    "    num_workers=num_workers_\n",
    "    train_bs=train_bs_\n",
    "    valid_bs=valid_bs_\n",
    "    data_dir = './'\n",
    "    INP_DIR = 'rsna/'\n",
    "    target_cols=[c+'_'+l+'_'+s for c in conditions for l in levels for s in severity]\n",
    "    imgs_dir = ['./input/']\n",
    "    num_classes=75\n",
    "\n",
    "    accum_iter=1#2\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    normalize_mean=[0.4824, 0.4824, 0.4824] # [0.485, 0.456, 0.406] [0.4824, 0.4824, 0.4824]\n",
    "    normalize_std=[0.22, 0.22, 0.22] # [0.229, 0.224, 0.225] [0.22, 0.22, 0.22]\n",
    "\n",
    "    suffix=\"440\"\n",
    "    fold_num=4\n",
    "    fold_list=[2, 3]\n",
    "    min_epoch = -1\n",
    "    epochs = 40\n",
    "    shift_epoch = 1000\n",
    "    model_arch=\"resnest50d\" # tf_efficientnetv2_s, resnest50d, resnext50_32x4d, resnet200d, convnext_tiny_384_in22ft1k\n",
    "    optimizer=\"AdamW\" # Adam, SGD, AdamW\n",
    "    scheduler=\"CosineAnnealingLR\"#'ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts'\n",
    "    loss_fn= \"Custom_loss\"#'Custom_loss', \"BCEWithLogitsLoss\", \"FocalLoss\"\n",
    "    scheduler_warmup=\"GradualWarmupSchedulerV3\" \n",
    "\n",
    "    warmup_epo=1\n",
    "    warmup_factor = 10\n",
    "    T_0 = 1\n",
    "    T_max= epochs-warmup_epo-2 \n",
    "    \n",
    "    seq_len = 90\n",
    "    img_size = 256\n",
    "    p_mixup = 0.5\n",
    "\n",
    "    lr=4e-5\n",
    "    min_lr=1e-7\n",
    "    # lr=23e-5\n",
    "    # min_lr=23e-6\n",
    "    weight_decay=0.02\n",
    "    dropout=0.1\n",
    "\n",
    "    gpu_parallel=False\n",
    "    n_early_stopping=8\n",
    "    debug=False\n",
    "    multihead=False\n",
    "    plane = 'sag_t1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [i for i in timm.list_models(pretrained=True) if 'resnest50d' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pandas -q\n",
    "# !pip install scikit-learn -q\n",
    "# !pip install warmup-scheduler==0.3 -q\n",
    "# !pip install timm==0.9.7 -q\n",
    "# !pip install albumentations==1.3.1\n",
    "# !pip install opencv-python -q\n",
    "# !pip install segmentation_models_pytorch\n",
    "# !apt-get update && apt-get install ffmpeg libsm6 libxext6  -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2435/4272702869.py:44: DeprecationWarning: Please import `zoom` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.ndimage.interpolation import zoom\n"
     ]
    }
   ],
   "source": [
    "import sys; \n",
    "\n",
    "package_paths = [f'{libdir}pytorch-image-models-master']\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "\n",
    "import ast\n",
    "from glob import glob\n",
    "# import cv2\n",
    "# from skimage import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from contextlib import contextmanager\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, StratifiedGroupKFold\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import timm\n",
    "import warnings\n",
    "import joblib\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "# import nibabel as nib\n",
    "# import pydicom as dicom\n",
    "import gc \n",
    "from torch.nn import DataParallel\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "\n",
    "if CFG.device == 'TPU':\n",
    "    !pip install -q pytorch-ignite\n",
    "    import ignite.distributed as idist\n",
    "elif CFG.device == 'GPU':\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()\n",
    "\n",
    "def torch_sigmoid(x): return (1 + (-x).exp()).reciprocal()\n",
    "\n",
    "\n",
    "class Custom_loss(nn.Module):\n",
    "    \n",
    "\n",
    "\n",
    "    def __init__(self, temperature=0.0):\n",
    "        \"\"\"\n",
    "        Use max if temperature = 0\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.t = temperature\n",
    "        assert self.t >= 0\n",
    "    def __repr__(self):\n",
    "        return 'SevereLoss(t=%.1f)' % self.t\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0], 25, 3).transpose(1, 2)\n",
    "\n",
    "        y = y.reshape(y.shape[0], 25, 3).transpose(1, 2).argmax(1)\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          y_pred (Tensor[float]): logit             (batch_size, 3, 25)\n",
    "          y      (Tensor[int]):   true label index  (batch_size, 25)\n",
    "        \"\"\"\n",
    "        assert y_pred.size(0) == y.size(0)\n",
    "        assert y_pred.size(1) == 3 and y_pred.size(2) == 25\n",
    "        assert y.size(1) == 25\n",
    "        assert y.size(0) > 0\n",
    "        slices = [slice(0, 5), slice(5, 15), slice(15, 25)] \n",
    "\n",
    "        loss = F.cross_entropy(y_pred, y.long(), reduction='none')  # (batch_size, 25)\n",
    "\n",
    "        wloss_sums = []\n",
    "        for k, idx in enumerate(slices):\n",
    "            wloss_sums.append((loss[:, idx]).sum())\n",
    "        y_spinal_prob = y_pred[:, :, :5].softmax(dim=1)             # (batch_size, 3,  5)\n",
    "\n",
    "        y_max = torch.amax(y[:, :5] == 2, dim=1).to(y_pred.dtype)   # 0 or 1\n",
    "        if self.t > 0:\n",
    "            # Attention for the maximum value\n",
    "            attn = F.softmax(y_spinal_prob[:, 2, :] / self.t, dim=1)  # (batch_size, 5)\n",
    "\n",
    "            # Pick the sofmax among 5 severe=2 y_spinal_probs with attn\n",
    "            y_pred_max = (attn * y_spinal_prob[:, 2, :]).sum(dim=1)   # weighted average among 5 spinal columns \n",
    "        else:\n",
    "            # Exact max; this works too\n",
    "            y_pred_max = y_spinal_prob[:, 2, :].amax(dim=1)\n",
    "        loss_max = F.binary_cross_entropy(y_pred_max, y_max, reduction='none')\n",
    "        wloss_sums.append((loss_max).sum())\n",
    "\n",
    "        # See below about these numbers\n",
    "        loss = (wloss_sums[0] / 6.084050632911392 +\n",
    "                wloss_sums[1] / 12.962531645569621 + \n",
    "                wloss_sums[2] / 14.38632911392405# +\n",
    "                # wloss_sums[3] / 1.729113924050633\n",
    "               ) / (3 * y.size(0))\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "def comp_metric_score(y_true, y_pred, w1 = 1, w2 = 1, apply_sig = True):\n",
    "    y_pred = sig(y_pred)\n",
    "    y_pred[:, 1::3] *= w1\n",
    "    y_pred[:, 2::3] *= w2\n",
    "    for i in range(0, 75, 3):\n",
    "        y_pred[:, i:i+3] /= y_pred[:, i:i+3].sum(1)[:, None]\n",
    "    y_pred = torch.from_numpy(y_pred)\n",
    "    y_pred = (torch.log(y_pred)/(1-y_pred))\n",
    "\n",
    "\n",
    "    y = torch.from_numpy(y_true.copy())\n",
    "    \n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], 25, 3).transpose(1, 2)\n",
    "    y = y.reshape(y.shape[0], 25, 3).transpose(1, 2).argmax(1)\n",
    "    # 4 losses for the evaluation metric\n",
    "    loss4_sum = torch.zeros(4)\n",
    "    w_sum = torch.zeros(4)\n",
    "    slices = [slice(0, 5), slice(5, 15), slice(15, 25)]  # spinal, foraminal, subarticular\n",
    "\n",
    "    w = 2 ** y  # sample_weight w = (1, 2, 4) for y = 0, 1, 2 (batch_size, 25)\n",
    "\n",
    "    batch_size = y_pred.shape[0]\n",
    "\n",
    "    ce_loss = F.cross_entropy(y_pred, y.long(), reduction='none')  # (batch_size, 25)\n",
    "    for k, idx in enumerate(slices):\n",
    "        w_sum[k] += w[:, idx].sum()\n",
    "        loss4_sum[k] += (w[:, idx] * ce_loss[:, idx]).sum()\n",
    "    # Spinal max\n",
    "    y_spinal_prob = y_pred[:, :, :5].softmax(dim=1)            # (batch_size, 3,  5)\n",
    "    w_max = torch.amax(w[:, :5], dim=1)                        # (batch_size, )\n",
    "    y_max = torch.amax(y[:, :5] == 2, dim=1).to(torch.float)   # 0 or 1\n",
    "    y_pred_max = y_spinal_prob[:, 2, :].amax(dim=1)            # max in severe (class=2)\n",
    "    loss_max = F.binary_cross_entropy(y_pred_max, y_max, reduction='none')\n",
    "    loss4_sum[3] += (w_max * loss_max).sum()\n",
    "    w_sum[3] += w_max.sum()\n",
    "    # Average over spinal, foraminal, subarticular, and any_severe_spinal\n",
    "    score = (loss4_sum / w_sum).sum().item() / 4\n",
    "    return score\n",
    "\n",
    "class Custom_loss2(nn.Module):\n",
    "\n",
    "    def forward(self, p, t):\n",
    "        p = p.sigmoid().reshape(-1, 25, 3)\n",
    "        p[..., 1] *= 2\n",
    "        p[..., 2] *= 4\n",
    "        p /= p.sum(2)[:,:,None]\n",
    "        p = p.reshape(-1, 75)\n",
    "        return F.binary_cross_entropy(p, t)\n",
    "\n",
    "def comp_metric_score2(y_true, y_pred, w1 = 1, w2 = 1, apply_sig = True):\n",
    "    t = y_true.copy()\n",
    "    p = y_pred.copy()\n",
    "    if apply_sig:\n",
    "        p = sig(p)\n",
    "    p[:, 1::3] *= w1\n",
    "    p[:, 2::3] *= w2\n",
    "    for i in range(0, 75, 3):\n",
    "        p[:,i:i+3] /= p[:,i:i+3].sum(1)[:, None]\n",
    "    t_sp, p_sp = t[:, :15].reshape(-1, 3), p[:, :15].reshape(-1, 3)\n",
    "    t_ne, p_ne = t[:, 15:45].reshape(-1, 3), p[:, 15:45].reshape(-1, 3)\n",
    "    t_su, p_su = t[:, 45:].reshape(-1, 3), p[:, 45:].reshape(-1, 3)\n",
    "    t_sp_sev, p_sp_sev = t[:, :15][:, 2::3].max(1), p[:, :15][:, 2::3].max(1)\n",
    "    loss_sp = log_loss(t_sp, p_sp, sample_weight = t_sp[:,0] + 2*t_sp[:,1]+4*t_sp[:, 2])\n",
    "    loss_ne = log_loss(t_ne, p_ne, sample_weight = t_ne[:,0] + 2*t_ne[:,1]+4*t_ne[:, 2])\n",
    "    loss_su = log_loss(t_su, p_su, sample_weight = t_su[:,0] + 2*t_su[:,1]+4*t_su[:, 2])\n",
    "    loss_sp_sev = log_loss(t_sp_sev, p_sp_sev)\n",
    "    print(loss_sp, loss_ne, loss_su, loss_sp_sev)\n",
    "    loss = (loss_sp + loss_ne + loss_su + loss_sp_sev)/4\n",
    "    print('w1 =', w1, 'w2 =', w2, loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENV = 'kaggle'\n",
    "if CFG.device == 'TPU':\n",
    "    import os\n",
    "    VERSION = \"1.7\"\n",
    "    CP_V = \"36\" if ENV == \"colab\" else \"37\"\n",
    "    wheel = f\"torch_xla-{VERSION}-cp{CP_V}-cp{CP_V}m-linux_x86_64.whl\"\n",
    "    url = f\"https://storage.googleapis.com/tpu-pytorch/wheels/{wheel}\"\n",
    "    !pip3 -q install cloud-tpu-client==0.10 $url\n",
    "    os.system('export XLA_USE_BF16=1')\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "    CFG.lr = CFG.lr * CFG.nprocs\n",
    "    CFG.train_bs = CFG.train_bs // CFG.nprocs\n",
    "    device = xm.xla_device()\n",
    "    \n",
    "elif CFG.device == \"GPU\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        score = roc_auc_score(y_true[:,i], y_pred[:,i])\n",
    "        scores.append(score)\n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score, scores\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=outputdir+'stage2_train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "if not os.path.isdir(outputdir):\n",
    "    os.mkdir(outputdir)\n",
    "LOGGER = init_logger(outputdir+f'/stage2_train{CFG.suffix}.log')\n",
    "\n",
    "if CFG.device=='TPU' and CFG.nprocs==8:\n",
    "    loginfo = xm.master_print\n",
    "    cusprint = xm.master_print\n",
    "else:\n",
    "    loginfo = LOGGER.info\n",
    "    cusprint = print\n",
    "\n",
    "\n",
    "\n",
    "def get_timediff(time1,time2):\n",
    "    minute_,second_ = divmod(time2-time1,60)\n",
    "    return f\"{int(minute_):02d}:{int(second_):02d}\"  \n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb\n",
    "\n",
    "def load_dicom(path):\n",
    "    \"\"\"\n",
    "    This supports loading both regular and compressed JPEG images. \n",
    "    See the first sell with `pip install` commands for the necessary dependencies\n",
    "    \"\"\"\n",
    "    img = dicom.dcmread(path)\n",
    "    img.PhotometricInterpretation = 'YBR_FULL'\n",
    "    data = img.pixel_array\n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    # data = (data * 255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, csv, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2, targets, mode, meta_features, in_chans, transform=None):\n",
    "\n",
    "        self.csv = csv.reset_index(drop=True)\n",
    "        self.ser_dict_sag_t1 = ser_dict_sag_t1\n",
    "        self.ser_dict_sag_t2 = ser_dict_sag_t2\n",
    "        self.ser_dict_ax_t2 = ser_dict_ax_t2\n",
    "        self.targets = targets\n",
    "        self.mode = mode\n",
    "        self.use_meta = meta_features is not None\n",
    "        self.meta_features = meta_features\n",
    "        self.transform = transform\n",
    "        self.in_chans = in_chans\n",
    "\n",
    "        self.aug_tr = v2.RandomRotation(\n",
    "                            degrees = (-45, 45),\n",
    "                            interpolation = torchvision.transforms.InterpolationMode.BILINEAR,\n",
    "                            expand = False,\n",
    "                            center = None,\n",
    "                            fill = 0\n",
    "                        )\n",
    "        self.aug_sj = v2.ScaleJitter(\n",
    "                        target_size = [CFG.img_size, CFG.img_size],\n",
    "                        scale_range = (0.8, 1.2),\n",
    "                        interpolation = torchvision.transforms.InterpolationMode.BILINEAR,\n",
    "                        antialias = True)\n",
    "        self.aug_rc = v2.RandomCrop(\n",
    "                            size = [CFG.img_size, CFG.img_size],\n",
    "                            #padding = None,\n",
    "                            pad_if_needed = True,\n",
    "                            fill = 0,\n",
    "                            padding_mode = 'constant'\n",
    "                        )\n",
    "        self.aug_hf = v2.RandomHorizontalFlip(0.5)\n",
    "        self.aug_vf = v2.RandomVerticalFlip(0.5)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = self.csv.iloc[index]\n",
    "\n",
    "\n",
    "        all_image = []\n",
    "        for plane in ['ax_t2', 'sag_t2']:#, 'sag_t1'\n",
    "\n",
    "            study_id = int(row.study_id)\n",
    "\n",
    "            if plane in ['sag_t1', 'sag_t2'] and study_id not in self.ser_dict_sag_t1.keys():\n",
    "                if self.mode == 'train':\n",
    "                    serie_id = np.random.choice(self.ser_dict_sag_t2[study_id])\n",
    "                else:\n",
    "                    serie_id = self.ser_dict_sag_t2[study_id][-1]\n",
    "            elif plane in ['sag_t1', 'sag_t2'] and study_id not in self.ser_dict_sag_t2.keys():\n",
    "                if self.mode == 'train':\n",
    "                    serie_id = np.random.choice(self.ser_dict_sag_t1[study_id])\n",
    "                else:\n",
    "                    serie_id = self.ser_dict_sag_t1[study_id][-1]\n",
    "            else:\n",
    "                if plane == 'sag_t1':\n",
    "                    if self.mode == 'train':\n",
    "                        serie_id = np.random.choice(self.ser_dict_sag_t1[study_id])\n",
    "                    else:\n",
    "                        serie_id = self.ser_dict_sag_t1[study_id][-1]\n",
    "                elif plane == 'sag_t2':\n",
    "                    if self.mode == 'train':\n",
    "                        serie_id = np.random.choice(self.ser_dict_sag_t2[study_id])\n",
    "                    else:\n",
    "                        serie_id = self.ser_dict_sag_t2[study_id][-1]\n",
    "                else:\n",
    "                    if self.mode == 'train':\n",
    "                        serie_id = np.random.choice(self.ser_dict_ax_t2[study_id])\n",
    "                    else:\n",
    "                        serie_id = self.ser_dict_ax_t2[study_id][-1]\n",
    "            if self.mode == 'train':\n",
    "                serie_id_ax_t2 = np.random.choice(self.ser_dict_ax_t2[study_id])\n",
    "            else:\n",
    "                serie_id_ax_t2 = self.ser_dict_ax_t2[study_id][-1]\n",
    "\n",
    "            fp = f'/dev/shm/preprocessed/{study_id}_{serie_id}.npy'\n",
    "            image = np.load(fp)\n",
    "    \n",
    "            image = torch.from_numpy(image).float()/255\n",
    "            image = F.interpolate(\n",
    "                     image.unsqueeze(0).unsqueeze(0),\n",
    "                     size=[CFG.seq_len, CFG.img_size, CFG.img_size],\n",
    "                     mode='trilinear'\n",
    "                 ).squeeze(0).squeeze(0)\n",
    "    \n",
    "            l_img = image.shape[0]\n",
    "            if (self.mode == 'train') and np.random.rand()<0.5:\n",
    "                image = self.aug_tr(image)\n",
    "                image = self.aug_sj(image)\n",
    "                image = self.aug_rc(image)\n",
    "    \n",
    "            l_img = image.shape[0]\n",
    "            if (self.mode == 'train') and np.random.rand()<0.5:\n",
    "                inds = np.random.choice(np.arange(l_img), CFG.seq_len)\n",
    "                inds.sort()\n",
    "                image = image[inds]\n",
    "            image = image.numpy()\n",
    "            tar = torch.tensor(row[self.targets]).float()\n",
    "\n",
    "            # transform\n",
    "            if self.transform:\n",
    "                \n",
    "                image = np.transpose(image, (1, 2, 0))\n",
    "                augmented = self.transform(image=image)\n",
    "                image = augmented['image']\n",
    "                image = np.transpose(image, (2, 0, 1))\n",
    "                image = torch.from_numpy(image)\n",
    "    \n",
    "\n",
    "            all_image.append(image)\n",
    "\n",
    "        image = torch.stack(all_image, -1)\n",
    "\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return study_id, image\n",
    "        else:\n",
    "            return study_id, image, torch.tensor(row[self.targets]).float()\n",
    "\n",
    "\n",
    "\n",
    "def get_transforms(*, data):\n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "    albumentations.Resize(CFG.img_size, CFG.img_size),\n",
    "    albumentations.Perspective(p=0.5),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.VerticalFlip(p=0.5),\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.RandomBrightness(limit=0.1, p=0.7),\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, border_mode=4, p=0.7),\n",
    "\n",
    "    albumentations.OneOf([\n",
    "        albumentations.MotionBlur(blur_limit=3),\n",
    "        albumentations.MedianBlur(blur_limit=3),\n",
    "        albumentations.GaussianBlur(blur_limit=3),\n",
    "        albumentations.GaussNoise(var_limit=(3.0, 9.0)),\n",
    "    ], p=0.5),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.OpticalDistortion(distort_limit=1.),\n",
    "        albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "    ], p=0.5),\n",
    "\n",
    "    albumentations.Cutout(max_h_size=int(CFG.img_size * 0.5), max_w_size=int(CFG.img_size * 0.5), num_holes=1, p=0.5),\n",
    "            ])\n",
    "    elif data == 'light_train':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.img_size, CFG.img_size),\n",
    "            A.Perspective(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, p=0.75),\n",
    "            A.OneOf(\n",
    "                [\n",
    "                    A.RandomGamma(p=1),\n",
    "                    A.RandomBrightnessContrast(contrast_limit=0.2, brightness_limit=0.0, p=1),\n",
    "                    A.RandomBrightnessContrast(contrast_limit=0.0, brightness_limit=0.2, p=1),\n",
    "                ],\n",
    "                p=0.5,\n",
    "            ),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(p = 1),\n",
    "                A.GaussianBlur(p = 1),\n",
    "                A.GaussNoise(p = 1),\n",
    "                ], p=0.5),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.05, p=0.5),\n",
    "            ], p=1.0)\n",
    "    elif data == 'valid':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.img_size, CFG.img_size),\n",
    "        ], p=1.0)\n",
    "\n",
    "def get_df():\n",
    "\n",
    "    df = pd.read_csv('train.csv')\n",
    "\n",
    "    for c in conditions:\n",
    "        for l in levels:\n",
    "            for s in severity:\n",
    "                df[c + '_' + l + '_' + s] =  (df[c + '_' + l] == s).astype(int)\n",
    "    df = df[['study_id']+CFG.target_cols]\n",
    "    tr_ser_desc = pd.read_csv('train_series_descriptions.csv')\n",
    "    ser_dict_sag_t1 = tr_ser_desc[tr_ser_desc['series_description']=='Sagittal T1'][['study_id', 'series_id']].groupby('study_id').apply(lambda df:df.series_id.tolist()).to_dict()\n",
    "    ser_dict_sag_t2 = tr_ser_desc[tr_ser_desc['series_description']=='Sagittal T2/STIR'][['study_id', 'series_id']].groupby('study_id').apply(lambda df:df.series_id.tolist()).to_dict()\n",
    "    ser_dict_ax_t2 = tr_ser_desc[tr_ser_desc['series_description']=='Axial T2'][['study_id', 'series_id']].groupby('study_id').apply(lambda df:df.series_id.tolist()).to_dict()\n",
    "    print(len(df), len(ser_dict_sag_t1), len(ser_dict_sag_t2), len(ser_dict_ax_t2))\n",
    "    skf = StratifiedGroupKFold(n_splits = CFG.fold_num)\n",
    "    df['fold'] = -1\n",
    "    for i, (train_inds, val_inds) in enumerate(skf.split(df, df[CFG.target_cols[-1]], df['study_id'])):\n",
    "        df.loc[val_inds, 'fold'] = i\n",
    "    return df, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from itertools import repeat\n",
    "\n",
    "class SpatialDropout(nn.Module):\n",
    "    def __init__(self, drop=0.5):\n",
    "        super(SpatialDropout, self).__init__()\n",
    "        self.drop = drop\n",
    "        \n",
    "    def forward(self, inputs, noise_shape=None):\n",
    "        \"\"\"\n",
    "        @param: inputs, tensor\n",
    "        @param: noise_shape, tuple\n",
    "        \"\"\"\n",
    "        outputs = inputs.clone()\n",
    "        if noise_shape is None:\n",
    "            noise_shape = (inputs.shape[0], *repeat(1, inputs.dim()-2), inputs.shape[-1]) \n",
    "        \n",
    "        self.noise_shape = noise_shape\n",
    "        if not self.training or self.drop == 0:\n",
    "            return inputs\n",
    "        else:\n",
    "            noises = self._make_noises(inputs)\n",
    "            if self.drop == 1:\n",
    "                noises.fill_(0.0)\n",
    "            else:\n",
    "                noises.bernoulli_(1 - self.drop).div_(1 - self.drop)\n",
    "            noises = noises.expand_as(inputs)    \n",
    "            outputs.mul_(noises)\n",
    "            return outputs\n",
    "            \n",
    "    def _make_noises(self, inputs):\n",
    "        return inputs.new().resize_(self.noise_shape)\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Dict, Optional\n",
    " \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "    \n",
    "class MLPAttentionNetwork(nn.Module):\n",
    " \n",
    "    def __init__(self, hidden_dim, attention_dim=None):\n",
    "        super(MLPAttentionNetwork, self).__init__()\n",
    " \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        if self.attention_dim is None:\n",
    "            self.attention_dim = self.hidden_dim\n",
    "        # W * x + b\n",
    "        self.proj_w = nn.Linear(self.hidden_dim, self.attention_dim, bias=True)\n",
    "        # v.T\n",
    "        self.proj_v = nn.Linear(self.attention_dim, 1, bias=False)\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: seq_len, batch_size, hidden_dim\n",
    "        :return: batch_size * seq_len, batch_size * hidden_dim\n",
    "        \"\"\"\n",
    "        # print(f\"x shape:{x.shape}\")\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        # flat_inputs = x.reshape(-1, self.hidden_dim) # (batch_size*seq_len, hidden_dim)\n",
    "        # print(f\"flat_inputs shape:{flat_inputs.shape}\")\n",
    "        \n",
    "        H = torch.tanh(self.proj_w(x)) # (batch_size, seq_len, hidden_dim)\n",
    "        # print(f\"H shape:{H.shape}\")\n",
    "        \n",
    "        att_scores = torch.softmax(self.proj_v(H),axis=1) # (batch_size, seq_len)\n",
    "        # print(f\"att_scores shape:{att_scores.shape}\")\n",
    "        \n",
    "        attn_x = (x * att_scores).sum(1) # (batch_size, hidden_dim)\n",
    "        # print(f\"attn_x shape:{attn_x.shape}\")\n",
    "        return attn_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6, p_trainable=False):\n",
    "        super(GeM, self).__init__()\n",
    "        if p_trainable:\n",
    "            self.p = nn.parameter.Parameter(torch.ones(1) * p)\n",
    "        else:\n",
    "            self.p = p\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        ret = gem(x, p=self.p, eps=self.eps)\n",
    "        return ret\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            self.__class__.__name__\n",
    "            + \"(\"\n",
    "            + \"p=\"\n",
    "            + \"{:.4f}\".format(self.p.data.tolist()[0])\n",
    "            + \", \"\n",
    "            + \"eps=\"\n",
    "            + str(self.eps)\n",
    "            + \")\"\n",
    "        )\n",
    "    \n",
    "    \n",
    "def drop_path(x, drop_prob: float = 0., training: bool = False, scale_by_keep: bool = True):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
    "\n",
    "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
    "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
    "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
    "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
    "    'survival rate' as the argument.\n",
    "\n",
    "    \"\"\"\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = x.new_empty(shape).bernoulli_(keep_prob)\n",
    "    if keep_prob > 0.0 and scale_by_keep:\n",
    "        random_tensor.div_(keep_prob)\n",
    "    return x * random_tensor\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob=None, scale_by_keep=True):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.scale_by_keep = scale_by_keep\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class RSNAClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, hidden_dim=256, seq_len=CFG.seq_len, pretrained=False, softmax = False, freeze_layers = True, fold = -1):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.fold = fold\n",
    "        self.model = timm.create_model(model_arch, in_chans=3, pretrained=pretrained)\n",
    "        self.model2 = timm.create_model(model_arch, in_chans=3, pretrained=pretrained)\n",
    "        self.softmax = softmax\n",
    "        self.freeze_layers = freeze_layers\n",
    "\n",
    "        cnn_feature = self.model.fc.in_features\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)#GeM(p_trainable=False)\n",
    "\n",
    "        self.model2.global_pool = nn.Identity()\n",
    "        self.model2.fc = nn.Identity()\n",
    "\n",
    "        self.spatialdropout = SpatialDropout(CFG.dropout)\n",
    "        self.gru = nn.GRU(cnn_feature, cnn_feature//2, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.gru2 = nn.GRU(cnn_feature, cnn_feature//2, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.mlp_attention_layers = nn.ModuleList([MLPAttentionNetwork(cnn_feature) for _ in range(5)])\n",
    "        self.mlp_attention_layers2 = nn.ModuleList([MLPAttentionNetwork(cnn_feature) for _ in range(5)])\n",
    "        self.logits = nn.ModuleList([nn.Sequential(\n",
    "                nn.Linear(2*cnn_feature, 512),\n",
    "                nn.Mish(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(512, 15),\n",
    "                ) for _ in range(5)])\n",
    "        self.logits2 = nn.ModuleList([nn.Sequential(\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(cnn_feature, 15),\n",
    "                ) for _ in range(5)])\n",
    "        self.logits3 = nn.ModuleList([nn.Sequential(\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(cnn_feature, 15),\n",
    "                ) for _ in range(5)])\n",
    "\n",
    "        if self.freeze_layers:\n",
    "            ws1 = torch.load(f'/dev/shm/rsna-v5/ax-t2/resnest50d_440_fold{self.fold}.pth')['model']\n",
    "            ws2 = torch.load(f'/dev/shm/rsna-v5/sag-t2/resnest50d_440_fold{self.fold}.pth')['model']\n",
    "            keys = list(ws1.keys())\n",
    "            for k in keys:\n",
    "                if not k.startswith('model.'):\n",
    "                    ws1.pop(k)\n",
    "                    ws2.pop(k)\n",
    "                else:\n",
    "                    ws1[k[6:]] = ws1.pop(k)\n",
    "                    ws2[k[6:]] = ws2.pop(k)\n",
    "            self.model.load_state_dict(ws1)\n",
    "            self.model2.load_state_dict(ws2)\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.model2.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            ws1 = torch.load(f'/dev/shm/rsna-v5/ax-t2/resnest50d_440_fold{self.fold}.pth')['model']\n",
    "            ws2 = torch.load(f'/dev/shm/rsna-v5/sag-t2/resnest50d_440_fold{self.fold}.pth')['model']\n",
    "            keys = list(ws1.keys())\n",
    "            for k in keys:\n",
    "                if not k.startswith('gru.'):\n",
    "                    ws1.pop(k)\n",
    "                    ws2.pop(k)\n",
    "                else:\n",
    "                    ws1[k[4:]] = ws1.pop(k)\n",
    "                    ws2[k[4:]] = ws2.pop(k)\n",
    "            self.gru.load_state_dict(ws1)\n",
    "            self.gru2.load_state_dict(ws2)\n",
    "            for param in self.gru.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.gru2.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            ws1 = torch.load(f'/dev/shm/rsna-v5/ax-t2/resnest50d_440_fold{self.fold}.pth')['model']\n",
    "            ws2 = torch.load(f'/dev/shm/rsna-v5/sag-t2/resnest50d_440_fold{self.fold}.pth')['model']\n",
    "            keys = list(ws1.keys())\n",
    "            for k in keys:\n",
    "                if not k.startswith('logits.'):\n",
    "                    ws1.pop(k)\n",
    "                    ws2.pop(k)\n",
    "                else:\n",
    "                    ws1[k[7:]] = ws1.pop(k)\n",
    "                    ws2[k[7:]] = ws2.pop(k)\n",
    "            self.logits2.load_state_dict(ws1)\n",
    "            self.logits3.load_state_dict(ws2)\n",
    "            for param in self.gru.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.gru2.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            ws1 = torch.load(f'/dev/shm/rsna-v5/ax-t2/resnest50d_440_fold{self.fold}.pth')['model']\n",
    "            ws2 = torch.load(f'/dev/shm/rsna-v5/sag-t2/resnest50d_440_fold{self.fold}.pth')['model']\n",
    "            keys = list(ws1.keys())\n",
    "            for k in keys:\n",
    "                if not k.startswith('mlp_attention_layers.'):\n",
    "                    ws1.pop(k)\n",
    "                    ws2.pop(k)\n",
    "                else:\n",
    "                    ws1[k[21:]] = ws1.pop(k)\n",
    "                    ws2[k[21:]] = ws2.pop(k)\n",
    "            self.mlp_attention_layers.load_state_dict(ws1)\n",
    "            self.mlp_attention_layers2.load_state_dict(ws2)\n",
    "            for param in self.mlp_attention_layers.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.mlp_attention_layers2.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x): # (B, seq_len, H, W)\n",
    "        bs = x.size(0)\n",
    "\n",
    "        x = x.reshape(bs*self.seq_len//3, 3, x.size(2), x.size(3), x.size(4)) # (B*seq_len, 1, H, W)\n",
    "        features = self.model(x[..., 0])\n",
    "        features2 = self.model2(x[..., 1])\n",
    "        if \"res\" in CFG.model_arch:                             \n",
    "            features = self.pooling(features).view(bs*self.seq_len//3, -1) # (B*seq_len, cnn_feature)\n",
    "            features2 = self.pooling(features2).view(bs*self.seq_len//3, -1) \n",
    "        features = features.reshape(bs, self.seq_len//3, -1)       # (B, seq_len, cnn_feature)\n",
    "        features2 = features2.reshape(bs, self.seq_len//3, -1)\n",
    "        features, _ = self.gru(features)                        # (B, seq_len, hidden_dim*2)\n",
    "        features2, _ = self.gru2(features2)\n",
    "        preds = []\n",
    "        for att_layer, att_layer2, logit, logit2, logit3 in zip(self.mlp_attention_layers, \n",
    "                                                            self.mlp_attention_layers2, \n",
    "                                                            self.logits, self.logits2, self.logits3):\n",
    "            p = att_layer(features)\n",
    "            p2 = att_layer2(features2)\n",
    "            p = logit(torch.cat([p, p2], -1))\n",
    "            preds.append(p)\n",
    "        preds = torch.cat(preds, -1)\n",
    "        if self.softmax:\n",
    "            preds = torch.cat([preds[:, i:i+3].softmax(1) for i in range(0, 75, 3)], -1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = RSNAClassifier(CFG.model_arch, hidden_dim=128, seq_len=CFG.seq_len, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_activation(activ_name: str=\"relu\"):\n",
    "    \"\"\"\"\"\"\n",
    "    act_dict = {\n",
    "        \"relu\": nn.ReLU(inplace=True),\n",
    "        \"tanh\": nn.Tanh(),\n",
    "        \"sigmoid\": nn.Sigmoid(),\n",
    "        \"identity\": nn.Identity()}\n",
    "    if activ_name in act_dict:\n",
    "        return act_dict[activ_name]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class Conv2dBNActiv(nn.Module):\n",
    "    \"\"\"Conv2d -> (BN ->) -> Activation\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_channels, out_channels,\n",
    "        kernel_size, stride, padding,\n",
    "        bias=False, use_bn=True, activ=\"relu\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(Conv2dBNActiv, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size, stride, padding, bias=bias))\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "        layers.append(get_activation(activ))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        return self.layers(x)\n",
    "        \n",
    "    \n",
    "class SpatialAttentionBlock(nn.Module):\n",
    "    \"\"\"Spatial Attention for (C, H, W) feature maps\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_channels,\n",
    "        out_channels_list,\n",
    "    ):\n",
    "        \"\"\"Initialize\"\"\"\n",
    "        super(SpatialAttentionBlock, self).__init__()\n",
    "        self.n_layers = len(out_channels_list)\n",
    "        channels_list = [in_channels] + out_channels_list\n",
    "        assert self.n_layers > 0\n",
    "        assert channels_list[-1] == 1\n",
    "        \n",
    "        for i in range(self.n_layers - 1):\n",
    "            in_chs, out_chs = channels_list[i: i + 2]\n",
    "            layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"relu\")\n",
    "            setattr(self, f\"conv{i + 1}\", layer)\n",
    "            \n",
    "        in_chs, out_chs = channels_list[-2:]\n",
    "        layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"sigmoid\")\n",
    "        setattr(self, f\"conv{self.n_layers}\", layer)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        h = x\n",
    "        for i in range(self.n_layers):\n",
    "            h = getattr(self, f\"conv{i + 1}\")(h)\n",
    "            \n",
    "        h = h * x\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadResNet200D(nn.Module):\n",
    "    def __init__(self, out_dims_head=[3, 4, 3, 1],  pretrained=False):\n",
    "        self.base_name = \"resnet200d_320\"\n",
    "        self.n_heads = len(out_dims_head)\n",
    "        super(MultiHeadResNet200D, self).__init__()\n",
    "        \n",
    "        # # load base model\n",
    "        base_model = timm.create_model(self.base_name, num_classes=sum(out_dims_head), pretrained=False)\n",
    "        in_features = base_model.num_features\n",
    "        \n",
    "        if pretrained:\n",
    "            pretrained_model_path = CFG.student\n",
    "            state_dict = dict()\n",
    "            for k, v in torch.load(pretrained_model_path, map_location='cpu')[\"model\"].items():\n",
    "                if k[:6] == \"model.\":\n",
    "                    k = k.replace(\"model.\", \"\")\n",
    "                state_dict[k] = v\n",
    "            base_model.load_state_dict(state_dict)\n",
    "        \n",
    "        # # remove global pooling and head classifier\n",
    "        base_model.reset_classifier(0, '')\n",
    "        \n",
    "        # # Shared CNN Bacbone\n",
    "        self.backbone = base_model\n",
    "        \n",
    "        # # Multi Heads.\n",
    "        for i, out_dim in enumerate(out_dims_head):\n",
    "            layer_name = f\"head_{i}\"\n",
    "            layer = nn.Sequential(\n",
    "                SpatialAttentionBlock(in_features, [64, 32, 16, 1]),\n",
    "                nn.AdaptiveAvgPool2d(output_size=1),\n",
    "                nn.Flatten(start_dim=1),\n",
    "                nn.Linear(in_features, in_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(in_features, out_dim))\n",
    "            setattr(self, layer_name, layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x)\n",
    "        hs = [getattr(self, f\"head_{i}\")(h) for i in range(self.n_heads)]\n",
    "        y = torch.cat(hs, axis=1)\n",
    "        return None, None, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup(input, truth, clip=[0, 1]):\n",
    "    indices = torch.randperm(input.size(0))\n",
    "    shuffled_input = input[indices]\n",
    "    shuffled_labels = truth[indices]\n",
    "\n",
    "    lam = np.random.uniform(clip[0], clip[1])\n",
    "    input = input * lam + shuffled_input * (1 - lam)\n",
    "    return input, truth, shuffled_labels, lam\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    if CFG.device == 'GPU':\n",
    "        scaler = GradScaler()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    for step, (study_id, images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        batch_size = labels.size(0)\n",
    "        \n",
    "        do_mixup = False\n",
    "        if random.random() < CFG.p_mixup:\n",
    "            do_mixup = True\n",
    "            images, labels, labels_mix, lam = mixup(images, labels)\n",
    "\n",
    "        if CFG.device == 'GPU':\n",
    "            # with autocast():\n",
    "            y_preds = model(images)\n",
    "            y_preds = y_preds.squeeze(1)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            if do_mixup:\n",
    "                loss11 = criterion(y_preds, labels_mix)\n",
    "                loss = loss * lam  + loss11 * (1 - lam)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.accum_iter > 1:\n",
    "                loss = loss / CFG.accum_iter\n",
    "            scaler.scale(loss).backward()\n",
    "            grad_norm = 0 # torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.accum_iter == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "        elif CFG.device == 'TPU':\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.accum_iter > 1:\n",
    "                loss = loss / CFG.accum_iter\n",
    "            loss.backward()\n",
    "            grad_norm = 0 # torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.accum_iter == 0:\n",
    "                xm.optimizer_step(optimizer, barrier=True)\n",
    "                optimizer.zero_grad()\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            cusprint('Epoch: [{0}][{1}/{2}] '\n",
    "                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                'Elapsed {remain:s} '\n",
    "                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                'Grad: {grad_norm:.4f}  '\n",
    "                'LR: {lr:.7f}  '\n",
    "                .format(\n",
    "                epoch, step, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses,\n",
    "                remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                grad_norm=grad_norm,\n",
    "                lr=optimizer.param_groups[0][\"lr\"],\n",
    "                ))\n",
    "        if(step == 0):print(loss)\n",
    "\n",
    "    return losses.avg, optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tta(images, nbr):\n",
    "    return torch.cat([images[:,nbr:,...], torch.cat(nbr*[images[:,-1:,...]], 1)], 1)\n",
    "\n",
    "\n",
    "def evaluate(y_preds, y_true, www = 1):\n",
    "    y_pred = torch.from_numpy(y_preds.copy())\n",
    "    y = torch.from_numpy(y_true.copy())\n",
    "    # loss0 = criterion(y_pred, y)\n",
    "    \n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], 25, 3).transpose(1, 2).softmax(dim=1)\n",
    "    if www==2:\n",
    "        y_pred[:, 1] *= 2\n",
    "        y_pred[:, 2] *= 4\n",
    "        y_pred /= y_pred.sum(1)[:, None]\n",
    "    y_pred = (torch.log(y_pred)/(1-y_pred))\n",
    "    y = y.reshape(y.shape[0], 25, 3).transpose(1, 2).argmax(1)\n",
    "\n",
    "    n_sum = 0\n",
    "    # loss0_sum = 0.0  # loss for the criterion\n",
    "    \n",
    "    # 4 losses for the evaluation metric\n",
    "    loss4_sum = torch.zeros(4)\n",
    "    w_sum = torch.zeros(4)\n",
    "    slices = [slice(0, 5), slice(5, 15), slice(15, 25)]  # spinal, foraminal, subarticular\n",
    "\n",
    "    w = 2 ** y  # sample_weight w = (1, 2, 4) for y = 0, 1, 2 (batch_size, 25)\n",
    "\n",
    "    batch_size = y_pred.shape[0]\n",
    "\n",
    "    n_sum += batch_size\n",
    "    # loss0_sum += loss0.item() * batch_size\n",
    "\n",
    "    # Compute score\n",
    "    # - weighted loss for spinal, foraminal, subarticular\n",
    "    # - binary cross entropy for maximum spinal severe\n",
    "    ce_loss = F.cross_entropy(y_pred, y.long(), reduction='none')  # (batch_size, 25)\n",
    "    for k, idx in enumerate(slices):\n",
    "        w_sum[k] += w[:, idx].sum()\n",
    "        loss4_sum[k] += (w[:, idx] * ce_loss[:, idx]).sum()\n",
    "    # Spinal max\n",
    "    y_spinal_prob = y_pred[:, :, :5].softmax(dim=1)            # (batch_size, 3,  5)\n",
    "    w_max = torch.amax(w[:, :5], dim=1)                        # (batch_size, )\n",
    "    y_max = torch.amax(y[:, :5] == 2, dim=1).to(torch.float)   # 0 or 1\n",
    "    y_pred_max = y_spinal_prob[:, 2, :].amax(dim=1)            # max in severe (class=2)\n",
    "\n",
    "    loss_max = F.binary_cross_entropy(y_pred_max, y_max, reduction='none')\n",
    "    loss4_sum[3] += (w_max * loss_max).sum()\n",
    "    w_sum[3] += w_max.sum()\n",
    "    # Average over spinal, foraminal, subarticular, and any_severe_spinal\n",
    "    score = (loss4_sum / w_sum).sum().item() / 4\n",
    "    print('weight =', www, 'evaluation score =', score)\n",
    "\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "def valid_one_epoch(valid_loader, model, criterion, device, softmax = False):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    trues = []\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (study_id, images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)#(model(images) + model(tta(images, 1)))/2\n",
    "            y_preds = y_preds.squeeze(1)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        # y_preds = y_preds.reshape(-1, 25, 3).softmax(dim=2).reshape(-1, 75)\n",
    "        trues.append(labels.to('cpu').numpy())\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            cusprint('EVAL: [{0}/{1}] '\n",
    "                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                'Elapsed {remain:s} '\n",
    "                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                .format(\n",
    "                step, len(valid_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses,\n",
    "                remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                ))\n",
    "\n",
    "    trues = np.concatenate(trues)\n",
    "    predictions = np.concatenate(preds)\n",
    "    sc = evaluate(predictions, trues, www = 1)\n",
    "    sc = evaluate(predictions, trues, www = 2)\n",
    "    print(f\"trues.shape: {trues.shape}\")\n",
    "    print(f\"predictions.shape: {predictions.shape}\")\n",
    "    if softmax:\n",
    "        score = nn.BCELoss()(torch.from_numpy(predictions).type(torch.float32), torch.from_numpy(trues).type(torch.float32))\n",
    "        score2 = comp_metric_score(trues, predictions, apply_sig = False)\n",
    "        score3 = comp_metric_score(trues, predictions, w1 = 2, w2 = 4, apply_sig = False)\n",
    "    else:\n",
    "        score = nn.BCEWithLogitsLoss()(torch.from_numpy(predictions).type(torch.float32), torch.from_numpy(trues).type(torch.float32))\n",
    "        score2 = comp_metric_score(trues, predictions, apply_sig = True)\n",
    "        score3 = comp_metric_score(trues, predictions, w1 = 2, w2 = 4, apply_sig = True)\n",
    "        _ = comp_metric_score2(trues, predictions, w1 = 1, w2 = 1, apply_sig = True)\n",
    "        _ = comp_metric_score2(trues, predictions, w1 = 2, w2 = 4, apply_sig = True)\n",
    "\n",
    "    \n",
    "    return losses.avg, predictions, trues, score, score2, score3, sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss & optimizer & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GradualWarmupSchedulerV3(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV3, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(df, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2, fold):\n",
    "    loginfo(f\"========== fold: {fold} training ==========\")\n",
    "    df = df[df['study_id'].isin(ser_dict_sag_t2.keys())]\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = df[df['fold']!=fold].reset_index(drop=True)################################################\"[:700]\n",
    "    valid_folds = df[df['fold']==fold].reset_index(drop=True)\n",
    "    \n",
    "    softmax = False\n",
    "    if CFG.loss_fn == \"BCEWithLogitsLoss\":\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    elif CFG.loss_fn == 'Custom_loss':\n",
    "        cust = Custom_loss()\n",
    "        cust2 = nn.BCEWithLogitsLoss()\n",
    "        def criterion(y_pred, y):\n",
    "            return cust(y_pred, y)#0.75*cust(y_pred, y) + 0.25*cust2(y_pred, y)\n",
    "        # softmax = True\n",
    "    elif(CFG.loss_fn == 'FocalLoss'):\n",
    "        criterion = FocalLoss()\n",
    "\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2, CFG.target_cols, 'train', None, CFG.seq_len, transform=get_transforms(data='light_train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2, CFG.target_cols, 'valid', None, CFG.seq_len, transform=get_transforms(data='valid'))\n",
    "    if CFG.device == 'GPU':\n",
    "        # sampler_train = torch.utils.data.RandomSampler(ds_train_len)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs, shuffle=True, num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    elif CFG.device == 'TPU':\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=True)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.train_bs, sampler=train_sampler, drop_last=True, num_workers=CFG.num_workers)\n",
    "        valid_sampler = torch.utils.data.distributed.DistributedSampler(valid_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=False)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=CFG.valid_bs, sampler=valid_sampler, drop_last=False, num_workers=CFG.num_workers)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer & scheduler & loss\n",
    "    # ====================================================\n",
    "    # not checkpoint\n",
    "\n",
    "    model = RSNAClassifier(CFG.model_arch, hidden_dim=256, seq_len=CFG.seq_len, pretrained=True, softmax = softmax, fold = fold)\n",
    "\n",
    "        \n",
    "    if CFG.gpu_parallel:    \n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        model = DataParallel(model, device_ids=range(num_gpu))\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    # optimizer\n",
    "    if CFG.optimizer == \"AdamW\":\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            optimizer = AdamW(model.parameters(), lr=CFG.lr/CFG.warmup_factor, weight_decay=CFG.weight_decay) \n",
    "        else:\n",
    "            optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    if CFG.optimizer == \"Adam\":\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            optimizer = Adam(model.parameters(), lr=CFG.lr/CFG.warmup_factor, weight_decay=CFG.weight_decay) \n",
    "        else:\n",
    "            optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    if CFG.optimizer == \"SGD\":\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            optimizer = SGD(model.parameters(), lr=CFG.lr/CFG.warmup_factor, weight_decay=CFG.weight_decay) \n",
    "        else:\n",
    "            optimizer = SGD(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    # scheduler,\n",
    "    if CFG.scheduler=='ReduceLROnPlateau':\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "    elif CFG.scheduler=='CosineAnnealingLR':\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "    elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "\n",
    "    scheduler_warmup = GradualWarmupSchedulerV3(optimizer, multiplier=CFG.warmup_factor, total_epoch=CFG.warmup_epo, after_scheduler=scheduler)\n",
    "\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    valid_acc_max=0; valid_loss_min=float(\"inf\")\n",
    "    valid_acc_max_cnt=0; valid_loss_min_cnt=0;\n",
    "    best_acc_epoch=0;\n",
    "\n",
    "\n",
    "    best_score = 10000\n",
    "\n",
    "    shift_epoch = CFG.shift_epoch#(3*CFG.epochs)//4\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        if epoch == shift_epoch:\n",
    "            model_ = RSNAClassifier(CFG.model_arch, hidden_dim=256, seq_len=CFG.seq_len, pretrained=True, softmax = True)\n",
    "            model_.to(device)\n",
    "            model_.load_state_dict(model.state_dict())\n",
    "            model = model_\n",
    "            criterion = Custom_loss()\n",
    "            softmax = True\n",
    "            optimizer_ = AdamW(model.parameters(), lr=CFG.lr/CFG.warmup_factor, weight_decay=CFG.weight_decay) \n",
    "            optimizer_.load_state_dict(optimizer.state_dict())\n",
    "            optimizer = optimizer_\n",
    "\n",
    "        loginfo(f\"***** Epoch {epoch} *****\")\n",
    "\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            loginfo(f\"schwarmup_last_epoch:{scheduler_warmup.last_epoch}, schwarmup_lr:{scheduler_warmup.get_last_lr()[0]}\")\n",
    "        if CFG.scheduler=='CosineAnnealingLR':\n",
    "            loginfo(f\"scheduler_last_epoch:{scheduler.last_epoch}, scheduler_lr:{scheduler.get_last_lr()[0]}\")\n",
    "        loginfo(f\"optimizer_lr:{optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        if(epoch>=CFG.min_epoch):\n",
    "            avg_loss, cur_lr = train_one_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device) # train\n",
    "        else:\n",
    "            avg_loss, cur_lr = -1, -1\n",
    "            # model.load_state_dict(torch.load(outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}.pth')['model'])\n",
    "            ws = torch.load(outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}.pth')['model']\n",
    "            ws2 = model.state_dict()\n",
    "            ws2.update(ws)\n",
    "            model.load_state_dict(ws2)\n",
    "        avg_val_loss, preds, trues, score, score2, score3, score4 = valid_one_epoch(valid_loader, model, criterion, device, softmax = softmax) # valid\n",
    "\n",
    "        # scoring\n",
    "        elapsed = time.time() - start_time \n",
    "\n",
    "        loginfo(f'Epoch {epoch} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        loginfo(f'Epoch {epoch} - avg_val_loss: {avg_val_loss:.4f} - avg_val_bce: {score:.4f} - avg_val_comp_metric : {score2:.4f} - w_avg_val_comp_metric : {score3:.4f}')\n",
    "\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            scheduler_warmup.step()\n",
    "        elif CFG.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif CFG.scheduler in [\"CosineAnnealingLR\", \"CosineAnnealingWarmRestarts\"]:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        if best_score>score4:\n",
    "            best_score = score4\n",
    "            ws = model.state_dict()\n",
    "            keys = list(ws.keys())\n",
    "            for k in keys:\n",
    "                if not k.startswith('logits.'):\n",
    "                    ws.pop(k)   \n",
    "\n",
    "            np.save(outputdir+f'/{CFG.model_arch}_{CFG.suffix}__fold{fold}_preds.npy', preds)\n",
    "            np.save(outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_trues.npy', trues)\n",
    "            torch.save({'model': model.state_dict()}, outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}.pth')\n",
    "\n",
    "    return preds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    oof_df = pd.DataFrame()\n",
    "    oof_list = []\n",
    "    train_df, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2 = get_df()\n",
    "    for fold in CFG.fold_list:\n",
    "        preds, trues = train_loop(train_df, ser_dict_sag_t1, ser_dict_sag_t2, ser_dict_ax_t2, fold)\n",
    "        oof_list.append([preds, trues])\n",
    "    return oof_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "1975 1973 1974 1975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "***** Epoch 0 *****\n",
      "schwarmup_last_epoch:0, schwarmup_lr:4.000000000000001e-06\n",
      "scheduler_last_epoch:0, scheduler_lr:4.000000000000001e-06\n",
      "optimizer_lr:4.000000000000001e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/124] Data 2.650 (2.650) Elapsed 0m 4s (remain 9m 29s) Loss: 0.3225(0.3225) \n",
      "EVAL: [100/124] Data 0.000 (0.027) Elapsed 0m 27s (remain 0m 6s) Loss: 0.1677(0.2664) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - avg_train_loss: -1.0000  time: 34s\n",
      "Epoch 0 - avg_val_loss: 0.2659 - avg_val_bce: 0.2866 - avg_val_comp_metric : 0.5717 - w_avg_val_comp_metric : 0.6060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [123/124] Data 0.000 (0.022) Elapsed 0m 33s (remain 0m 0s) Loss: 0.4243(0.2659) \n",
      "weight = 1 evaluation score = 0.4868314862251282\n",
      "weight = 2 evaluation score = 0.4496035873889923\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n",
      "0.37545499555141904 0.6329692830344926 0.6920404889397052 0.2238256192243744\n",
      "w1 = 1 w2 = 1 0.4810725966874978\n",
      "0.42799708826052957 0.677373465639109 0.7139865400216576 0.2715328903303016\n",
      "w1 = 2 w2 = 4 0.5227224960628994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 1 training ==========\n",
      "***** Epoch 0 *****\n",
      "schwarmup_last_epoch:0, schwarmup_lr:4.000000000000001e-06\n",
      "scheduler_last_epoch:0, scheduler_lr:4.000000000000001e-06\n",
      "optimizer_lr:4.000000000000001e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/124] Data 1.780 (1.780) Elapsed 0m 2s (remain 4m 8s) Loss: 0.2583(0.2583) \n",
      "EVAL: [100/124] Data 0.000 (0.046) Elapsed 0m 28s (remain 0m 6s) Loss: 0.3685(0.2667) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - avg_train_loss: -1.0000  time: 35s\n",
      "Epoch 0 - avg_val_loss: 0.2672 - avg_val_bce: 0.2846 - avg_val_comp_metric : 0.5752 - w_avg_val_comp_metric : 0.6149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [123/124] Data 0.000 (0.054) Elapsed 0m 35s (remain 0m 0s) Loss: 0.1548(0.2672) \n",
      "weight = 1 evaluation score = 0.489918977022171\n",
      "weight = 2 evaluation score = 0.4580690562725067\n",
      "trues.shape: (494, 75)\n",
      "predictions.shape: (494, 75)\n",
      "0.3949338888394965 0.6322290339972138 0.6847042906480152 0.23156905676606712\n",
      "w1 = 1 w2 = 1 0.48585906756269814\n",
      "0.4504792091523381 0.6850357642090823 0.6970852225038795 0.3118136058382566\n",
      "w1 = 2 w2 = 4 0.5361034504258891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 2 training ==========\n",
      "***** Epoch 0 *****\n",
      "schwarmup_last_epoch:0, schwarmup_lr:4.000000000000001e-06\n",
      "scheduler_last_epoch:0, scheduler_lr:4.000000000000001e-06\n",
      "optimizer_lr:4.000000000000001e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/124] Data 1.711 (1.711) Elapsed 0m 1s (remain 3m 59s) Loss: 0.2738(0.2738) \n",
      "EVAL: [100/124] Data 0.000 (0.017) Elapsed 0m 25s (remain 0m 5s) Loss: 0.2395(0.2772) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - avg_train_loss: -1.0000  time: 31s\n",
      "Epoch 0 - avg_val_loss: 0.2714 - avg_val_bce: 0.2937 - avg_val_comp_metric : 0.5786 - w_avg_val_comp_metric : 0.6153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [123/124] Data 0.000 (0.014) Elapsed 0m 30s (remain 0m 0s) Loss: 0.0173(0.2714) \n",
      "weight = 1 evaluation score = 0.48960524797439575\n",
      "weight = 2 evaluation score = 0.45944106578826904\n",
      "trues.shape: (493, 75)\n",
      "predictions.shape: (493, 75)\n",
      "0.38750533387626196 0.6462525656347464 0.6952088928470364 0.2363541466187582\n",
      "w1 = 1 w2 = 1 0.49133023474420073\n",
      "0.4410903447950007 0.6991291426936865 0.7036998545783477 0.3146752227070914\n",
      "w1 = 2 w2 = 4 0.5396486411935316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 3 training ==========\n",
      "***** Epoch 0 *****\n",
      "schwarmup_last_epoch:0, schwarmup_lr:4.000000000000001e-06\n",
      "scheduler_last_epoch:0, scheduler_lr:4.000000000000001e-06\n",
      "optimizer_lr:4.000000000000001e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/124] Data 1.296 (1.296) Elapsed 0m 1s (remain 3m 9s) Loss: 0.2563(0.2563) \n",
      "EVAL: [100/124] Data 0.000 (0.014) Elapsed 0m 24s (remain 0m 5s) Loss: 0.1479(0.2671) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - avg_train_loss: -1.0000  time: 30s\n",
      "Epoch 0 - avg_val_loss: 0.2667 - avg_val_bce: 0.2928 - avg_val_comp_metric : 0.5673 - w_avg_val_comp_metric : 0.6155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [123/124] Data 0.000 (0.011) Elapsed 0m 30s (remain 0m 0s) Loss: 0.2137(0.2667) \n",
      "weight = 1 evaluation score = 0.4696274399757385\n",
      "weight = 2 evaluation score = 0.44606131315231323\n",
      "trues.shape: (493, 75)\n",
      "predictions.shape: (493, 75)\n",
      "0.38481526732235677 0.6307844676861583 0.6958750236136952 0.20944457217865944\n",
      "w1 = 1 w2 = 1 0.48022983270021746\n",
      "0.4630939858948766 0.7022556809934897 0.6936760374492577 0.29453082265925085\n",
      "w1 = 2 w2 = 4 0.5383891317492187\n"
     ]
    }
   ],
   "source": [
    "CFG.epochs = 12\n",
    "CFG.min_epoch = -1\n",
    "\n",
    "# CFG.epochs = 1\n",
    "# CFG.min_epoch = 1\n",
    "\n",
    "CFG.plane = 'sag-t2'\n",
    "CFG.fold_list = [0, 1, 2, 3]\n",
    "outputdir = f'output_all'\n",
    "seed_everything(42)\n",
    "if not os.path.isdir(outputdir):\n",
    "    os.mkdir(outputdir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(CFG.suffix)\n",
    "    if CFG.device == 'TPU':\n",
    "        def _mp_fn(rank, flags):\n",
    "            torch.set_default_tensor_type('torch.FloatTensor')\n",
    "            a = main()\n",
    "        FLAGS = {}\n",
    "        xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=CFG.nprocs, start_method='fork')\n",
    "    elif CFG.device == 'GPU':\n",
    "        oof_list = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2261054437.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[27], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    weight = 2 evaluation score = 0.44960105419158936\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "weight = 2 evaluation score = 0.44960105419158936\n",
    "weight = 2 evaluation score = 0.45807141065597534\n",
    "weight = 2 evaluation score = 0.4594390392303467\n",
    "weight = 2 evaluation score = 0.4460652470588684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
